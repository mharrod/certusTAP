{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Pre-Alpha</p> Trust &amp; Assurance Platform  <p>Certus TAP is an open framework that unifies security, integrity, privacy, and assurance into a verifiable and continous pipeline that proves your system can be trusted.</p> Explore the framework Join the community"},{"location":"community/","title":"Community","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and community a harassment-free experience for everyone \u2014 regardless of age, body size, disability, ethnicity, sex characteristics, gender identity or expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"community/#our-standards","title":"Our Standards","text":"<p>Examples of behaviour that contribute to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language  </li> <li>Being respectful of differing viewpoints and experiences  </li> <li>Gracefully accepting constructive criticism  </li> <li>Focusing on what is best for the community  </li> <li>Showing empathy toward other community members  </li> </ul>"},{"location":"community/#contributing","title":"Contributing","text":"<p>There are many ways to contribute. If you have an idea, a workflow improvement, or something others might find useful:</p> <ul> <li>You can email your idea to certustap@gmail.com </li> <li>Better yet. Share it directly in our Zulip community workspace.  </li> </ul> <p>Join our Zulip community: \ud83d\udc49 https://certus.zulipchat.com</p> <p>Once you\u2019re there: - Post in the #general stream to introduce yourself. - Use topic threads (e.g., ideas, help-wanted, assurance-pipeline, etc.) to keep discussions organized. - Feel free to ask questions, propose features, or share interesting findings.</p>"},{"location":"community/#contact-us","title":"Contact Us","text":"<p>We use Zulip as our primary space for community discussion and support.</p> <ul> <li>Main Workspace: https://certus.zulipchat.com </li> <li>Email: certustap@gmail.com</li> </ul> <p>It\u2019s open to everyone \u2014 please join and say hello!</p>"},{"location":"community/#community-meetings","title":"Community Meetings","text":"<p>Our community operates primarily through asynchronous communication in Zulip. Occasionally, we host live calls or collaborative sessions for key initiatives or releases.</p> <p>Announcements for all-hands calls and special events will be posted in the #announcements stream on Zulip.</p> <p>If you\u2019d like to organize a meeting or propose a topic for discussion, reach out via Zulip</p>"},{"location":"community/#code-of-conduct","title":"Code of Conduct","text":"<p>Participation in this community implies agreement to our Code of Conduct </p> <p>We expect all interactions to align with the same principles of respect, inclusively, and constructive collaboration described above.</p>"},{"location":"community/conduct/","title":"Code of Conduct","text":"<p>We are committed to providing a welcoming and inspiring community for everyone. This Code of Conduct outlines our expectations for all participants in our community, both online and in-person, as well as the consequences for unacceptable behavior.</p>"},{"location":"community/conduct/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and community a harassment\u2011free experience for everyone, regardless of:</p> <ul> <li>Age, body size, disability, ethnicity</li> <li>Sex characteristics, gender identity or expression</li> <li>Level of experience, education, socio\u2011economic status</li> <li>Nationality, personal appearance, race, religion</li> <li>Sexual identity or orientation</li> </ul> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"community/conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people  </li> <li>Being respectful of differing opinions, viewpoints, and experiences  </li> <li>Giving and gracefully accepting constructive feedback  </li> <li>Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience  </li> <li>Focusing on what is best not just for us as individuals, but for the overall community  </li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or advances of any kind  </li> <li>Trolling, insulting or derogatory comments, and personal or political attacks  </li> <li>Public or private harassment  </li> <li>Publishing others\u2019 private information, such as a physical or email address, without their explicit permission  </li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting  </li> </ul>"},{"location":"community/conduct/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned with this Code of Conduct, or to ban temporarily or permanently any contributor for behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"community/conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces and also applies when an individual is officially representing the community in public spaces. Examples include using an official project email address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"community/conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at certustap@gmail.com. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All project team members are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"community/conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Project maintainers will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct.</p>"},{"location":"community/conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from project maintainers, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"community/conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces and external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"community/conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period.</p>"},{"location":"community/conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"community/conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at: https://www.contributor-covenant.org/version/2/1/code_of_conduct.html</p> <p>For answers to common questions about this code of conduct, see the FAQ at: https://www.contributor-covenant.org/faq</p>"},{"location":"framework/","title":"Certus TAP","text":"<p>Certus Trust &amp; Assurance Platform (CertusTAP)  aims to be a unified open framework for evaluating, enriching, and governing software and AI systems through automation, evidence, and selective human review.  We want to create a language of assurance that both humans and systems can use to underscore trust.</p> <p>At the moment the goal is to use this platform to combine Security, Integrity, Privacy, and AI Assurance testing into a single automated flow. It ensures every artifact, whether code, container, dataset, or model, is scanned, normalized, enriched with context and threat data, evaluated by policy, and stored as immutable evidence in a locked down OCI repository.  The architecture is designed for immutability, traceability, and human-in-the-loop (HITL) oversight where judgment is required.</p> Click to view Architecture <p></p> <p>Ultimately, some of the use cases we hope to tackle with this approach include but are not limited to:</p> <ul> <li>Prove software integrity through automated build attestations and signed provenance.</li> <li>Continuously validate security posture with embedded scanning and evidence collection.</li> <li>Detect and mitigate privacy risks using automated PII and data-handling analysis.</li> <li>Govern AI behavior via bias, fairness, and transparency evaluations built into the workflow.</li> <li>Map controls to frameworks (SOC 2, NIST, ISO, AI Act) to generate machine-readable compliance evidence.</li> <li>Enable selective human review where ethical or contextual judgment is required.</li> <li>Maintain a living evidence trail linking code, model, and policy decisions to measurable proof.</li> <li>Unify assurance language across humans and systems through standardized metadata and schemas.</li> <li>Provide the data, metrics, and integrations for organizations preferred compliance tooling to generate real-time trust dashboards summarizing compliance, risk, and integrity metrics.</li> <li>Facilitate continuous audit readiness by automating evidence generation and storage.</li> <li>Support secure supply-chain validation with verifiable SBOMs and dependency attestations.</li> <li>Bridge development and governance so assurance is built in\u2014not bolted on.</li> <li>Empower external stakeholders (regulators, customers, partners) with transparent, verifiable trust artifacts.</li> <li>Drive accountability by codifying human decisions and approvals into the assurance record.</li> <li>Foster ecosystem collaboration  through open, machine-interpretable assurance specifications.</li> </ul>"},{"location":"framework/architecture/","title":"Architecture","text":"Click to view Architecture"},{"location":"framework/architecture/#1-assurance-manifest","title":"1. Assurance Manifest","text":"<p>Purpose: The declarative control layer that defines assurance scope, configurations, and required checks. It describes what systems, tests, and policies are to be run, and acts as the canonical \u201ccontract\u201d for an assurance run.</p> <p>Responsibilities:</p> <ul> <li>Declare systems, models, and artifacts under test  </li> <li>Reference applicable policies, frameworks, and thresholds  </li> <li>Define metadata (owners, risk context, environments)  </li> <li>Produce signed assurance manifests sent to the OCI registry</li> </ul>"},{"location":"framework/architecture/#2-pipeline-orchestration","title":"2. Pipeline Orchestration","text":"<p>Purpose: The control layer that runs and coordinates all scanning, enrichment, and gating tasks. Examples: Dagger, GitHub Actions, Tekton, GitLab CI/CD, or any workflow orchestrator.</p> <p>Responsibilities:</p> <ul> <li>Schedule and execute the assurance stages  </li> <li>Manage data flow between scanners, normalizers, enrichers, and gates  </li> <li>Ensure each step emits signed evidence artifacts  </li> </ul>"},{"location":"framework/architecture/#3-systems-under-test","title":"3. Systems Under Test","text":"<p>Purpose: The targets being evaluated \u2014 can be application code, AI models, datasets, configurations, or deployed systems.  </p> <p>Examples:</p> <ul> <li>Source repositories (code)</li> <li>Trained AI models (<code>.onnx</code>, <code>.pt</code>, <code>.safetensors</code>)</li> <li>Cloud workloads (VMs, clusters)</li> <li>Data assets or ETL pipelines  </li> </ul> <p>Output: Artifacts ready for scanning.</p>"},{"location":"framework/architecture/#4-scanning-assurance-testing-tooling","title":"4. Scanning \u2014 Assurance Testing Tooling","text":"<p>Scanners identify security flaws, policy violations, or data risks across multiple assurance domains.</p> Category Example Tools Focus Security SAST, DAST, SCA, IaC Vulnerabilities, misconfigurations Integrity Sigstore, SLSA, Falco Provenance, tamper detection, drift Privacy Presidio, Macie, Great Expectations PII leakage, data masking, privacy risk AI Assurance PyRIT, AIF360, DeepEval, Guardrails Bias, fairness, hallucination, unsafe output <p>Each scanner produces structured output (e.g., SARIF, JSON, or custom format).</p>"},{"location":"framework/architecture/#5-normalization","title":"5. Normalization","text":"<p>Purpose: Converts heterogeneous scanner results into a consistent schema for downstream analysis.</p> <p>Key Tasks:</p> <ul> <li>Schema Alignment: Convert outputs (SARIF preferred) to a standard model  </li> <li>Fingerprinting: Assign unique IDs to findings (to track persistence across runs)  </li> <li>Severity Mapping: Standardize severities (e.g., map \u201ccritical\u201d \u2192 CVSS 9\u201310)</li> </ul> <p>Output Example: <pre><code>{\n  \"fingerprint\": \"abc123\",\n  \"severity\": \"high\",\n  \"source\": \"snyk\",\n  \"target\": \"service-a\",\n  \"file\": \"src/main.py\"\n}\n</code></pre></p>"},{"location":"framework/architecture/#6-enrichment","title":"6. Enrichment","text":""},{"location":"framework/architecture/#a-contextual-enrichment","title":"A. Contextual Enrichment","text":"<p>Adds business, operational, and traceability context.</p> Field Description Severity Finalized severity after normalization Component or Service Derived from repo or deployment manifest Evidence URI (Placeholder) Temporary identifier that will later point to the signed OCI evidence Additional Labels e.g., <code>tool:snyk</code>, <code>env:prod</code>, <code>team:payments</code>"},{"location":"framework/architecture/#b-threat-enrichment","title":"B. Threat Enrichment","text":"<p>Adds external risk intelligence and threat context.</p> Field Description CVSS / CWE / CPE Classification and scoring references Exploit Available? Indicates known exploit existence EPSS Score Probability of exploitation Patch Available Boolean flag for fixability Vulnerability Score Composite risk score based on contextual + threat data"},{"location":"framework/architecture/#7-policy-gate-policy-decision","title":"7. Policy Gate (Policy Decision)","text":"<p>Purpose: The automated evaluation checkpoint where findings are tested against defined policies. Implemented as: Code-based policy (CUE, Rego, or OPA rules).</p> <p>Core Inputs:</p> <ul> <li>Normalized and enriched findings  </li> <li>Policy definitions and thresholds  </li> <li>Optional human approvals (from previous runs)</li> </ul> Policy Description SEC-001 No critical vulnerabilities in production without valid waiver INT-002 Artifacts must have valid Sigstore signature PRV-003 Privacy risk score must be \u2264 0.5 AI-004 Model bias must be \u2264 0.2 or requires review <p>Outputs:</p> <ul> <li>Pass: All rules satisfied \u2192 pipeline proceeds automatically  </li> <li>Fail: One or more violations detected \u2192 triggers Human-in-the-Loop  </li> </ul>"},{"location":"framework/architecture/#8-human-in-the-loop-hitl","title":"8. Human in the Loop (HITL)","text":"<p>Purpose: Manual approval or override for exceptions requiring judgment.</p> <p>Triggered by:</p> <ul> <li>Known exploited vulnerabilities (KEV = true)</li> <li>High EPSS (\u2265 0.7)</li> <li>Critical/High findings in production</li> <li>Potential false positives</li> </ul> <p>Process:</p> <ol> <li>Gate pauses and sends a review request (ticket or form)  </li> <li>Reviewer assesses evidence and approves or rejects  </li> <li>Approved waivers are signed and stored as OCI artifacts  </li> <li>Pipeline resumes and re-evaluates the gate with approval context  </li> </ol> <p>Evidence Type Example:</p> <pre><code>{\n  \"type\": \"approval\",\n  \"approved_by\": \"seclead@example.com\",\n  \"scope\": \"finding:abc123\",\n  \"expires_at\": \"2025-11-05\"\n}\n</code></pre>"},{"location":"framework/architecture/#9-outputs-and-evidence-management","title":"9. Outputs and Evidence Management","text":"<p>After passing the policy gate (either automatically or with approval), the pipeline produces three main evidence outputs.</p>"},{"location":"framework/architecture/#a-metrics","title":"A. Metrics","text":"<p>Aggregated quantitative data (counts, trends, severities, scores). Used for visualization and continuous monitoring. Examples: vulnerability counts by team, mean time to approval, bias trendline.</p>"},{"location":"framework/architecture/#b-ticket-management","title":"B. Ticket Management","text":"<p>Issues and findings are synchronized into a project management tool (e.g., OpenProject, Jira). Each ticket links to its Evidence URI in the OCI registry. Supports remediation tracking and SLA management.</p>"},{"location":"framework/architecture/#c-artifacts-oci-registry","title":"C. Artifacts (OCI Registry)","text":"<p>The canonical storage for all signed evidence: - Normalized results - Enrichment data - Policy evaluation output - Human approvals  </p> <p>Each artifact is immutable and referenced by a digest (e.g., <code>oci://assurance/findings@sha256:...</code>).</p>"},{"location":"framework/architecture/#10-visualization-dashboards","title":"10. Visualization &amp; Dashboards","text":"<p>Visualization: Feeds from Metrics for reporting and analytics. Commonly implemented via Grafana or similar dashboards.</p> <p>Dashboard (Governance View): </p> <p>Feeds from Ticket Management for operational tracking. Provides audit-ready evidence of exceptions, open risks, and assurance status.</p>"},{"location":"framework/architecture/#11-trustcentre","title":"11. TrustCentre","text":"<p>Purpose: The cryptographic and identity backbone of the assurance framework \u2014 ensuring that all evidence, policies, and approvals are verifiable, timestamped, and immutable.</p> <p>Components:</p> Component Description Sign / Verify Handles digital signatures (Cosign, KMS, or keyless Sigstore). Every artifact, manifest, and waiver is signed before publishing. WORM-Compliant OCI Write-Once, Read-Many (WORM)\u2013compliant OCI registry that guarantees immutability for stored evidence (e.g., Harbor, ORAS, GCP Artifact Registry). Transparency Enables public or internal verifiability of evidence chains using transparency logs (e.g., Rekor) or Merkle proofs. Provenance Records the lineage of all artifacts \u2014 mapping \u201cwho, what, when, how\u201d for every piece of evidence. Audit Ledger A verifiable event log that records all pipeline operations, human approvals, and gate evaluations for audit readiness. Timestamp RFC 3161\u2013compliant timestamps to bind evidence to trusted time anchors. Key &amp; Identity Management Integrates enterprise KMS, OIDC identity providers, and Vault for secure key material and policy-based signing. Supports threshold signatures and delegated authority (e.g., policy keys). <p>Output: Signed, timestamped, and provenance-linked artifacts that form the root of trust for the entire assurance ecosystem.</p>"},{"location":"framework/architecture/#12-ai-reasoning","title":"12. AI Reasoning","text":"<p>Purpose: Provides semantic analysis, correlation, and higher-order reasoning across all assurance artifacts using AI models. Acts as the \u201cassurance intelligence\u201d layer that can interpret evidence, generate insights, and assist reviewers.</p> <p>Core Modules:</p> Module Description Retrievers Query vector databases or OCI manifests to locate relevant evidence, policies, and prior run history. Fusion Logic Aggregates multi-source evidence and correlates findings (e.g., linking a vulnerability with its exploit probability and waiver context). LLM Chain Executes large language model (LLM) workflows \u2014 e.g., summarizing findings, generating assurance narratives, or classifying risks. Schema &amp; Safety Gates Enforces guardrails ensuring AI outputs adhere to expected schema, bias limits, and factual consistency before being published. Agent Orchestrator Coordinates specialized AI agents (e.g., risk summarizer, waiver validator, or privacy auditor) and routes tasks between them. <p>Responsibilities:</p> <ul> <li>Perform context-aware analysis across structured and unstructured assurance data  </li> <li>Generate natural language summaries for dashboards and auditors  </li> <li>Run DeepEval or equivalent frameworks to evaluate AI-generated outputs for accuracy and safety  </li> <li>Contribute derived metrics (e.g., hallucination rate, bias delta, model drift) to Metrics and Visualization layers  </li> </ul> <p>Output: AI-augmented reasoning traces and structured evidence summaries, stored in the OCI registry and linked to Assurance Chatbot.</p>"},{"location":"framework/architecture/#13-assurance-chatbot","title":"13. Assurance Chatbot","text":"<p>Purpose: Human\u2013machine interface that allows engineers, auditors, and stakeholders to query assurance evidence conversationally.</p> <p>Key Functions:</p> <ul> <li>Interactive Querying: Retrieve artifacts and metrics via natural language (e.g., \u201cShow all privacy waivers approved in Q4\u201d).  </li> <li>Context-Aware Assistance: Uses retrievers and fusion logic from the AI Reasoning layer to explain findings, waivers, or policy outcomes.  </li> <li>Provenance-Aware Responses: All chatbot outputs reference verifiable Evidence URIs (never hallucinated data).  </li> <li>Human Feedback Loop: Allows auditors to flag discrepancies or provide annotations, which become part of the next enrichment cycle.  </li> </ul> <p>Example Interaction:</p> <p>User: \u201cWhy was SEC-001 waived for Service X?\u201d Chatbot: \u201cWaiver approved by seclead@example.com on 2025-11-05, linked to Finding abc123 (CVSS 9.1). Evidence URI: <code>oci://assurance/waivers@sha256:...</code>.\u201d</p> <p>Backend Integration:</p> <ul> <li>Pulls from OCI registry, metrics store, and ticket system  </li> <li>Uses LLM Chain + Schema/Safety Gates to ensure outputs remain accurate and non-speculative  </li> <li>Logs every query and response for audit traceability  </li> </ul>"},{"location":"framework/architecture/#14-evidence-traceability","title":"14. Evidence &amp; Traceability","text":"<p>Every step produces signed or attestable evidence.</p> Step Evidence Type Storage Scanning Raw scanner reports Temporary workspace Normalization Normalized SARIF OCI Registry Enrichment Contextual + Threat JSON OCI Registry Policy Decision Gate results + policy version OCI Registry HITL Approval artifact OCI Registry Outputs Aggregated metrics &amp; dashboards Monitoring systems <p>All evidence URIs are included in tickets and metrics, ensuring end-to-end traceability.</p>"},{"location":"framework/architecture/#15-key-design-principles","title":"15. Key Design Principles","text":"Principle Description Immutable Evidence All artifacts are signed and stored immutably (OCI digests). Policy-as-Code Rules are versioned, testable, and reviewed like software. Human-in-the-Loop Humans intervene only where judgment is required. Continuous Enrichment Findings are dynamically enriched with internal and external context. Unified Schema SARIF (or equivalent) ensures interoperability across scanners. Auditability Each decision is traceable from source to signature."},{"location":"framework/architecture/#16-optional-extensions","title":"16. Optional Extensions","text":"Extension Description Integrity Drift Monitor Continuously verify that deployed workloads match signed artifacts. Privacy Regression Suite Run privacy checks before every dataset or model update. AI Evaluation Metrics Integrate hallucination rate, bias delta, explainability score. Continuous Feedback Loop Feed metrics back into developer dashboards and risk scoring models."},{"location":"framework/architecture/#summary","title":"Summary","text":"<p>This pipeline provides a single source of truth for security, integrity, privacy, and AI assurance. It turns what were once siloed checks into a cohesive, auditable, and policy-driven control plane. By combining automation + human oversight + immutable evidence, this model enables organizations to achieve:</p> <ul> <li>Continuous compliance  </li> <li>Measurable trust  </li> <li>Real-time visibility across all assurance dimensions</li> </ul>"},{"location":"framework/principles/","title":"Principles","text":"<p>This platform is intentionally designed as a framework, specification, and ontology not a prescriptive product. Its purpose is to define how assurance should work, not what specific tools must be used.  We hope to provide a common language and structure for continuous assurance.  If you will, a modular blueprint that any organization can implement using the technologies and processes that best fit their environment.</p>"},{"location":"framework/principles/#benefits-of-the-this-approach","title":"Benefits of the this Approach","text":"<ul> <li>Flexibility: Teams can start small and expand. You can swap scanners, ticketing systems, or registries without redesigning the pipeline underlying the platform.</li> <li>Portability: Works across cloud, on-prem, or hybrid environments.</li> <li>Interoperability: Encourages open standards (SARIF, OCI, SLSA, JSON-LD) instead of proprietary formats.</li> <li>Governance Consistency: Even if implementations differ, the assurance model and ontology stays the same.</li> <li>Future-Proofing: As new tools emerge, they can be plugged into existing stages with minimal friction.</li> </ul> <p>Here is what we encourage everyone to keep in mind as we build this out:</p>"},{"location":"framework/principles/#core-principles","title":"Core Principles","text":""},{"location":"framework/principles/#1-start-with-the-evidence-not-the-ticket","title":"1. Start with the Evidence, Not the Ticket","text":"<p>Your Ticket Management System (TMS) is not your source of truth. It is your collaboration layer. The source of truth is the immutable evidence store:</p> <ul> <li>Each scanner (OpenGrep, ZAP, Trivy, Grype, etc.) outputs a signed SARIF or JSON file.  </li> <li>Those files are stored in an OCI registry or a WORM-locked bucket, indexed by content digest.  </li> <li>You can always reproduce, verify, and attest to what was found, when, and by which tool.  </li> <li>Your ticket system should simply reference that evidence, rather than owning it.  </li> </ul> <p>Example: <code>Evidence: ghcr.io/org/app@sha256:abcd.../trivy.sarif</code> </p> <p>That single line in every ticket creates an unbreakable chain of custody between your human process and the machine-verifiable proof.</p>"},{"location":"framework/principles/#2-normalize-once-then-reuse-everywhere","title":"2. Normalize Once, Then Reuse Everywhere","text":"<p>Most scanners already support SARIF, the industry\u2019s lingua franca for security results. Instead of letting each scanner speak its own dialect, build a tiny \u201cnormalizer\u201d job in your CI pipeline that:</p> <ul> <li>Merges and enriches results with metadata (commit, image digest, branch, environment).  </li> <li>Computes deterministic fingerprints so findings can be de-duplicated across runs.  </li> <li>Emits a canonical JSON structure that any downstream system \u2014 Jira, Grafana, or a data lake \u2014 can consume. {u6t5r4ewdsqa    dfergt |?qx    } This is your Normalization Layer. Everything above it (TMS, dashboards, metrics) is replaceable. Everything below it (SARIF, SBOMs, attestations) is immutable.</li> </ul>"},{"location":"framework/principles/#3-replace-the-platform-with-a-simple-sync-layer","title":"3. Replace the \u201cPlatform\u201d With a Simple Sync Layer","text":"<p>Once you\u2019ve normalized your data, the integration with a TMS is surprisingly straightforward.</p> <p>Your CI/CD pipeline (or a scheduled job) can:</p> <ol> <li>Parse the normalized SARIF.  </li> <li>Derive a unique key per finding (e.g., ruleId + location).  </li> <li>Query your workload/ticket system for an issue with that key in a custom field or label.  </li> <li>Create or update the issue as needed.  </li> </ol> <p>Example pseudo-logic:</p> <pre><code>fingerprint = sha1(ruleId + file + line)\nif not tms.issue_exists(fingerprint):\n    tms.create_issue(summary, description, severity, fingerprint)\nelse:\n    tms.comment_issue(fingerprint, \"Still open in commit abc123\")\n</code></pre> <p>This approach gives you the same automation you\u2019d expect from a dedicated vulnerability platform \u2014 but using lightweight code you control.</p> <p>You can even enrich issues with contextual metadata:</p> <ul> <li>Severity: mapped from the scanner  </li> <li>Component or Service: derived from repository or manifest  </li> <li>Commit / PR: for developer traceability  </li> <li>Evidence URI: immutable link to SARIF  </li> <li>Labels: <code>tool:semgrep</code>, <code>env:prod</code>, <code>scanner:v1.8</code> </li> </ul> <p>Now your TMS becomes a thin, flexible interface for triage and remediation \u2014 not a bloated database.</p>"},{"location":"framework/principles/#4-keep-it-immutable-even-in-your-tms","title":"4. Keep It Immutable, even in Your TMS","text":"<p>Immutability doesn\u2019t stop at storage. It\u2019s a philosophy that should extend all the way to your workflow.</p> <p>Here\u2019s how to preserve that principle:</p> <ul> <li>Don\u2019t edit findings manually. Update them only by re-running scans and re-syncing.  </li> <li>Never overwrite. If a vulnerability reappears, record it as a state change (\u201cre-opened\u201d), not a fresh ticket.  </li> <li>Keep digests, not filenames. References like <code>sha256:abcd...</code> ensure long-term verifiability.  </li> <li>Sign your syncs. Each batch of issues you create or update can be wrapped in an attestation (<code>cosign attest</code>) listing input digests and timestamps.  </li> </ul> <p>This turns a process like vulnerability management into a cryptographically provable audit trail, not a spreadsheet of opinions.</p>"},{"location":"framework/principles/#5-automate-the-metrics","title":"5. Automate the Metrics","text":"<p>Once you decouple your evidence from your workflow, metrics become trivial.</p> <p>A small exporter service can query your ticket system (or your normalized JSON store) and expose metrics such as:</p> <pre><code>security_findings_open{severity=\"critical\"} 3\nsecurity_findings_sla_breached_total 1\nsecurity_last_scan_timestamp_seconds{repo=\"api\"} 1696883400\n</code></pre> <p>A tool like Grafana can then visualize:</p> <ul> <li>Open findings by severity or service  </li> <li>Mean Time to Remediate (MTTR)  </li> <li>Aging of unresolved issues  </li> <li>Scan freshness per environment  </li> </ul> <p>These metrics drive your conversations \u2014 not subjective dashboards or PDF reports.</p>"},{"location":"framework/principles/#6-enforce-policy-as-code","title":"6. Enforce Policy as Code","text":"<p>With everything in Git and everything signed, policy enforcement becomes a simple gate.  </p> <p>Use CUE or OPA to define your security SLOs:</p> <ul> <li>\u201cCritical findings = 0\u201d  </li> <li>\u201cNo unresolved Highs older than 30 days\u201d  </li> <li>\u201cLast scan &lt; 24h old\u201d  </li> </ul> <p>Evaluate those policies in CI/CD before promotion. Fail the deployment if any condition isn\u2019t met.  </p> <p>That\u2019s real continuous assurance \u2014 automated, auditable, and provable.</p>"},{"location":"framework/principles/#7-design-for-verifiability-not-just-visibility","title":"7. Design for Verifiability, Not Just Visibility","text":"<p>Dashboards show what\u2019s happening; verifiability proves it. Every output should be independently checkable  by an auditor, a developer, or an external regulator.</p> <ul> <li>Prefer signed attestations to unsigned reports.  </li> <li>Record policy version, scanner version, and timestamp for every result.  </li> <li>Enable re-verification (replayability) from artifact digests without re-running scans.  </li> </ul> <p>This ensures your assurance pipeline produces proofs, not just reports.</p>"},{"location":"framework/principles/#8-embrace-composability-over-centralization","title":"8. Embrace Composability Over Centralization","text":"<p>Avoid the \u201csingle platform\u201d trap \u2014 your ecosystem should be modular, not monolithic.</p> <ul> <li>Build around open standards (SARIF, SPDX, OPA, OCI).  </li> <li>Each component (scanner, normalizer, sync, visualizer) can be swapped without breaking the chain.  </li> <li>Encourage integration through API contracts and schema stability, not through UI lock-in.  </li> </ul> <p>This philosophy keeps your system resilient to vendor churn and technological drift.</p>"},{"location":"framework/principles/#9-treat-assurance-as-a-feedback-loop","title":"9. Treat Assurance as a Feedback Loop","text":"<p>Assurance isn\u2019t a one-way audit; it\u2019s a continuous learning cycle.</p> <ul> <li>Feed enriched metrics (MTTR, false-positive rate, bias score, etc.) back into scanner configuration and policy thresholds.  </li> <li>Automatically tune or retire ineffective rules.  </li> <li>Use AI-based triage or clustering to guide developers toward high-value remediations first.  </li> </ul> <p>The goal is adaptive improvement, not static compliance.</p>"},{"location":"framework/principles/#10-build-for-multi-persona-collaboration","title":"10. Build for Multi-Persona Collaboration","text":"<p>Different participants \u2014 developers, auditors, data scientists, compliance officers \u2014 all view \u201crisk\u201d differently.</p> <ul> <li>Deliver context-appropriate surfaces (e.g., Jira tickets for devs, Grafana dashboards for ops, signed ledgers for auditors).  </li> <li>Maintain a shared vocabulary through consistent metadata fields (e.g., <code>severity</code>, <code>component</code>, <code>evidence_uri</code>).  </li> <li>Keep human review paths explicit, auditable, and reversible.  </li> </ul> <p>This avoids the common trap of one-size-fits-all \u201csecurity portals.\u201d</p>"},{"location":"framework/principles/#11-assume-policy-tooling-and-ai-drift","title":"11. Assume Policy, Tooling, and AI Drift","text":"<p>Every system you integrate \u2014 scanners, AI validators, even governance policies \u2014 will evolve. Design for graceful drift rather than brittle coupling.</p> <ul> <li>Version everything (schemas, policies, prompts, AI models).  </li> <li>Persist results with their context (model hash, policy commit, scanner version).  </li> <li>Periodically re-evaluate historical evidence with updated logic to maintain continuity across generations.  </li> </ul> <p>This provides temporal assurance: what was compliant last year can still be verified under today\u2019s rules.</p>"},{"location":"framework/principles/#12-make-ai-optional-keep-humans-in-the-loop","title":"12. Make AI Optional, Keep Humans in the Loop","text":"<p>AI can accelerate assurance \u2014 summarizing evidence, highlighting anomalies, or assisting triage \u2014 but it must never become a single point of failure or authority.  </p> <ul> <li>Treat AI as a copilot, not a controller. Its role is to augment human judgment, not replace it.  </li> <li>Every AI output (classification, reasoning trace, recommendation) should be traceable, explainable, and verifiable via supporting evidence.  </li> <li>Always allow human override \u2014 approvals, waivers, and sign-offs must remain cryptographically attributable to a person or policy key.  </li> <li>Build the pipeline so that AI components can be disabled entirely without breaking the assurance flow.  </li> <li>Log both AI prompts and responses in your immutable evidence store for accountability and reproducibility.  </li> </ul> <p>The goal isn\u2019t to make assurance \u201cautonomous\u201d; it\u2019s to make it assistive, auditable, and reversible \u2014 where every automated insight still ends in a human\u2019s informed decision.</p>"},{"location":"framework/ontology/","title":"The TAO of CertusTAP","text":""},{"location":"framework/ontology/#the-vision","title":"The Vision","text":"<p>Certus TAO transforms assurance from a static audit into a living knowledge graph of trust where  every artifact carries its own verifiable provenance and proof of integrity. It forms the foundation of a machine-understandable Trust Center, where  evidence, reasoning, and signatures converge to makes assurance explainable and verifiable \u2014 by both humans and machines. It is A Semantic Framework for Machine-Verifiable Trust </p> <p> Read the TAO specification</p>"},{"location":"framework/ontology/#the-background","title":"The Background","text":"<p>Modern organizations generate vast amounts of assurance evidence such as vulnerability scans, AI model evaluations, provenance logs, attestations, and risk assessments. However, these artifacts are often siloed, inconsistent, and lack a shared structure. The Certus Trust &amp; Assurance Ontology (TAO) defines a unified language for trust that enables systems, auditors, and AI agents to understand, reason about, and prove that digital systems are secure, ethical, and trustworthy. It captures how trust is built, evidenced, and validated across the assurance lifecycle using cryptographic, analytical, and procedural evidence. Certus TAO\u2019s goal is to connect them in a semantic knowledge graph that can answer questions like:</p> <ul> <li>\u201cWhat evidence supports this claim of fairness or compliance?\u201d  </li> <li>\u201cWho signed this attestation and when?\u201d  </li> <li>\u201cWhich policies does this artifact satisfy?\u201d  </li> <li>\u201cCan we prove this model\u2019s provenance and ethical compliance?\u201d</li> </ul>"},{"location":"framework/ontology/#ontology-summary","title":"Ontology Summary","text":"<p>Certus TAO models the entities, artifacts, evidence, and relationships that define digital trust.</p> Concept Description Example Entity Actor, person, or organization producing or signing artifacts. ACME Labs, Independent Auditor Artifact Object under assurance (software, model, dataset, report). Model v2.0, Build Artifact Evidence Proof supporting a claim. Bias Test Report, Security Scan Results Claim Statement requiring evidence. \u201cModel is bias-mitigated.\u201d Policy / Control Normative rule or standard requirement. ISO 27001, NIST 800-53, AI Fairness Policy Evaluation Assessment producing metrics or scores. DeepEval run, Privacy Scan Assurance Case Structured argument linking claims and evidence. AI Model Assurance Case Trust Proof Verifiable output (attestation, signed proof). Cosign signature, RFC3161 timestamp Risk Identified issue with impact and mitigation. PII exposure risk Signature / Timestamp Cryptographic verification artifacts. Cosign keyless sig, TSA token <p>Together, these form a semantic web of assurance \u2014 every artifact is traceable to its origin, evidence, and proof.</p>"},{"location":"framework/ontology/#role-within-certus-tap","title":"Role Within Certus TAP","text":"Goal How Certus TAO Enables It Continuous Assurance Every scan, evaluation, or attestation becomes a trust node in the ontology. Traceability &amp; Provenance Each artifact links to its producer, build, and assurance evidence. Automation &amp; Reasoning Ontology rules enable inference of compliance or detection of missing evidence. Explainability &amp; Auditability Auditors can see why something is trusted through linked evidence and claims. Integration Harmonizes Haystack, Presidio, DeepEval, and Cosign outputs under one schema. Governance &amp; Interoperability Aligns with W3C PROV-O, ISO 15026, and NIST OSCAL standards."},{"location":"framework/ontology/#how-it-works","title":"How It Works","text":"<ol> <li> <p>Evidence Generation    Tools like Presidio, DeepEval, and scanners produce structured results.    \u2192 Annotated as <code>tao:Evidence</code>, <code>tao:Evaluation</code>, or <code>tao:Risk</code>.</p> </li> <li> <p>Semantic Linking    Each artifact, claim, and policy is connected using ontology relationships:</p> </li> </ol> <pre><code>Artifact \u2192 hasEvidence \u2192 Evidence \u2192 supportsClaim \u2192 Claim \u2192 satisfiesPolicy \u2192 Policy\n</code></pre> <ol> <li> <p>Reasoning &amp; Validation    Using OWL or SHACL logic, TAO enables reasoning such as: \u201cIf an artifact\u2019s evidence supports a claim that satisfies a policy, then that artifact is compliant.\u201d</p> </li> <li> <p>Publication &amp; Verification    Results (trust proofs, attestations) are signed and published to a WORM OCI registry \u2014 forming immutable assurance records.</p> </li> <li> <p>Visualization &amp; Querying    The trust graph can be queried via SPARQL or visualized in dashboards to demonstrate compliance and provenance.</p> </li> </ol>"},{"location":"framework/ontology/#integration-examples","title":"Integration Examples","text":"System Ontology Role Haystack 2 Provides the reasoning and RAG interface; each document is semantically annotated using TAO. Presidio Generates privacy assurance evidence (<code>tao:Evidence</code>). DeepEval Produces evaluation metrics (<code>tao:Evaluation</code> with <code>scoreType</code> and <code>scoreValue</code>). Cosign / Rekor Creates <code>tao:TrustProof</code>, <code>tao:Signature</code>, and <code>tao:Timestamp</code> for cryptographic verification. OCI Evidence Registry Stores verifiable assurance cases and attestations."},{"location":"framework/ontology/#why-it-matters","title":"Why It Matters","text":"<ul> <li>Trust becomes measurable \u2014 every claim is backed by structured evidence.  </li> <li>AI becomes explainable \u2014 assurance lineage is visible end-to-end.  </li> <li>Security becomes provable \u2014 provenance and signatures are verifiable.  </li> <li>Compliance becomes continuous \u2014 validation happens automatically.  </li> <li>Collaboration becomes semantic \u2014 humans and machines share a common assurance language.</li> </ul> <p>Author: TAO Working Draft Maintainer: Martin Harrod License: Creative Commons Attribution 4.0 International (CC-BY 4.0)  </p>"},{"location":"framework/ontology/tao/","title":"Certus TAO","text":"<p>Trust &amp; Assurance Ontology (TAO) Version: 0.1 Last Updated: 2025-10-16  </p> <p>Namespace: <code>https://certus.tap/ontology/tao#</code> </p>"},{"location":"framework/ontology/tao/#overview","title":"Overview","text":"<p>The Trust &amp; Assurance Ontology (TAO) provides a semantic framework for describing, linking, and reasoning about trust, assurance, provenance, and evidence across AI and security systems.  It integrates principles from W3C PROV-O, ISO/IEC 15026 (Assurance Cases), and NIST OSCAL to support interoperable assurance pipelines.</p>"},{"location":"framework/ontology/tao/#core-classes","title":"Core Classes","text":"Class Description Example Entity Actor or agent participating in assurance activities. <code>ACME Labs</code>, <code>Auditor</code> Artifact Produced object under evaluation or assurance. <code>AI Model</code>, <code>Dataset</code>, <code>Source Code</code> Evidence Proof supporting a claim or requirement. <code>Bias Report</code>, <code>Pen Test</code>, <code>Policy Evaluation</code> Claim Statement requiring supporting evidence. \u201cModel is bias-tested.\u201d Policy Normative rule or standard requirement. <code>FairnessPolicy2025</code>, <code>ISO27001 A.12.4</code> Control Atomic implementation of a policy requirement. <code>NIST AC-2</code>, <code>SOC2 Security Principle</code> Evaluation Assessment activity or metric result. <code>DeepEval Run</code>, <code>CVSS Scan</code>, <code>Fairness Check</code> AssuranceCase Structured argument linking claims and evidence. \u201cBias mitigation verified for Model X.\u201d TrustProof Verifiable summary or attestation derived from an assurance case. <code>Cosign Attestation</code>, <code>Signed Waiver</code> Attestation Signed cryptographic proof asserting compliance. <code>SLSA Provenance Attestation</code> Risk Identified concern with impact and mitigation. <code>Model Bias</code>, <code>Unverified Signature</code> Signature Digital signature binding an entity to an artifact. <code>Cosign Keyless Signature</code> Timestamp Cryptographic timestamp (e.g., RFC 3161). <code>TSA Token</code> AuditEvent Logged event relevant to trust or governance. <code>Model Validation Logged</code>"},{"location":"framework/ontology/tao/#relationships","title":"Relationships","text":"Relationship Domain \u2192 Range Description <code>produces</code> Entity \u2192 Artifact Entity produces an artifact under assurance. <code>generatedBy</code> Artifact \u2192 Activity Artifact generated by a process or build. <code>hasEvidence</code> Artifact \u2192 Evidence Artifact is supported by assurance evidence. <code>supportsClaim</code> Evidence \u2192 Claim Evidence backs up a claim. <code>satisfiesPolicy</code> Claim \u2192 Policy Claim fulfills a policy or control. <code>validates</code> Evaluation \u2192 Evidence Evaluation confirms or tests evidence. <code>aggregates</code> AssuranceCase \u2192 Claim Assurance case bundles multiple claims. <code>derivesFrom</code> TrustProof \u2192 AssuranceCase Trust proof is derived from an assurance case. <code>impacts</code> Risk \u2192 Artifact Risk affects an artifact. <code>mitigates</code> Control \u2192 Risk Control reduces risk likelihood or impact. <code>signedBy</code> TrustProof \u2192 Entity Proof is signed by an entity. <code>hasProvenance</code> Artifact \u2192 Entity Provenance link to source or origin. <code>referencesArtifact</code> Evidence \u2192 Artifact Evidence refers to specific artifact. <code>hasMetric</code> Evaluation \u2192 Document Evaluation produces a measurable result. <code>aboutArtifact</code> AssuranceCase \u2192 Artifact Assurance case concerns specific artifact. <code>hasSignature</code> TrustProof \u2192 Signature Trust proof includes a digital signature. <code>hasTimestamp</code> TrustProof \u2192 Timestamp Trust proof includes a timestamp."},{"location":"framework/ontology/tao/#data-properties","title":"Data Properties","text":"Property Applies To Description <code>hasHash</code> Artifact Hash value (e.g., SHA256) of the artifact. <code>hasDigestAlgorithm</code> Artifact Algorithm used for hashing (e.g., SHA256). <code>hasURI</code> Artifact Canonical storage or OCI URI. <code>createdAt</code> Entity/Artifact Creation timestamp. <code>updatedAt</code> Entity/Artifact Last update timestamp. <code>scoreValue</code> Evaluation Numeric score (e.g., 0.94). <code>scoreType</code> Evaluation Metric type (<code>CVSS</code>, <code>DeepEval.Fairness</code>). <code>severity</code> Risk Severity descriptor (e.g., <code>High</code>, <code>Medium</code>). <code>status</code> Risk Status of the risk (<code>Open</code>, <code>Mitigated</code>)."},{"location":"framework/ontology/tao/#concept-map","title":"Concept Map","text":"<pre><code>graph TD\n  A[Entity: ACME Labs] --&gt;|produces| B[Artifact: Model X]\n  B --&gt;|hasEvidence| C[Evidence: Bias Report]\n  C --&gt;|supports| D[Claim: Bias Mitigated]\n  D --&gt;|satisfies| E[Policy: Fairness 2025]\n  D --&gt;|aggregatedIn| F[Assurance Case]\n  F --&gt;|derives| G[TrustProof: Signed Attestation]\n  G --&gt;|signedBy| A</code></pre>"},{"location":"framework/ontology/tao/#example-individuals","title":"Example Individuals","text":"<pre><code>:ModelX a tao:Model ;\n  tao:hasURI \"oci://trustcentre/org/product/modelx@sha256:abcd...\" ;\n  tao:hasHash \"abcd...\" ;\n  tao:hasDigestAlgorithm \"sha256\" ;\n  tao:hasEvidence :BiasReport1 .\n\n:BiasReport1 a tao:Evidence ;\n  tao:referencesArtifact :ModelX ;\n  tao:supportsClaim :ClaimBiasMitigated .\n\n:ClaimBiasMitigated a tao:Claim ;\n  tao:satisfiesPolicy :FairnessPolicy2025 .\n\n:FairnessPolicy2025 a tao:Policy ;\n  rdfs:label \"Fairness Policy 2025\"@en .\n</code></pre>"},{"location":"framework/ontology/tao/#external-mappings","title":"External Mappings","text":"External Standard TAO Alignment Example W3C PROV-O Provenance tracking for entities, artifacts, activities <code>prov:Entity</code>, <code>prov:Activity</code> ISO/IEC 15026 Assurance case structures <code>AssuranceCase</code>, <code>Claim</code>, <code>Evidence</code> NIST OSCAL Compliance and control linkage <code>Policy</code>, <code>Control</code>, <code>Risk</code> AI Model Cards / Datasheets Ethical &amp; performance evidence <code>Evidence</code>, <code>Evaluation</code>, <code>Metric</code> COSIGN / SLSA / Rekor Signed provenance and attestations <code>TrustProof</code>, <code>Signature</code>, <code>Timestamp</code>"},{"location":"framework/ontology/tao/#governance-notes","title":"Governance Notes","text":"<ul> <li>The ontology is designed to be extendable and alignable with domain-specific ontologies (e.g., Privacy, Safety, Fairness).  </li> <li>Versioning should follow semantic versioning (e.g., <code>0.1</code>, <code>0.2</code>, <code>1.0</code>).  </li> <li>Namespace convention: <code>https://certus.tap/ontology/tao#</code> </li> <li>Storage recommendation: Publish both <code>.ttl</code> and <code>.jsonld</code> versions in an open, queryable location (e.g., GitHub Pages or OCI registry).</li> </ul>"},{"location":"framework/ontology/tao/#future-extensions","title":"Future Extensions","text":"Area Planned Additions AI Ethics Bias, transparency, and accountability classes Security Zero Trust entity interactions, signature validation axioms Privacy PII detection evidence (Presidio integration) Governance Policy lineage, review records, and auditor roles <p>Author: TAO Working Draft Maintainer: Martin Harrod License: Creative Commons Attribution 4.0 International (CC-BY 4.0)  </p>"},{"location":"framework/workflows/","title":"Workflows","text":"<p>These workflows describe how actors within the assurance ecosystem interact to achieve specific objectives.  They capture who is involved, what each participant does, and why the interaction matters in maintaining trust and verifiable assurance.</p> <p>These workflows serve three main purposes:</p> <ol> <li> <p>Clarity and Communication    They provide a clear narrative of how assurance workflows function end to end, ensuring both technical and non-technical stakeholders understand the process.</p> </li> <li> <p>Traceability and Accountability    Each use case ties actions to identifiable actors, artifacts, and verification points \u2014 establishing the foundation for auditability and compliance.</p> </li> <li> <p>Design and Validation    They help model the expected system behavior, define boundaries of responsibility, and validate that assurance mechanisms align with the defined trust model.</p> </li> </ol>"},{"location":"framework/workflows/#relationship-to-the-diagrams","title":"Relationship to the Diagrams","text":"<p>Each use case in this section is paired with a Mermaid sequence diagram that visualizes the same scenario in an interaction format.   These diagrams depict the exchange of data, evidence, and verification messages between actors such as the System Under Test, AI Reasoner, Human Reviewer, and TrustCentre. </p> <p>The combination of narrative and visual flow enables readers to quickly understand both the intent and operational behavior of the assurance lifecycle \u2014 from data collection to signed, auditable outcomes.</p>"},{"location":"framework/workflows/assurance/","title":"Assurance &amp; Audit","text":""},{"location":"framework/workflows/assurance/#1-access-scope-definition","title":"1) Access &amp; Scope Definition","text":"<p>Review the sanitized findings.</p> Click to view <pre><code>sequenceDiagram\n    participant Auditor\n    participant Trust as TrustCentre\n    participant Vendor\n    participant Customer\n    autonumber\n\n    %% Step 1 - Access Request\n    Auditor-&gt;&gt;Trust: Request read only credentials to portal or API\n    Trust-&gt;&gt;Auditor: Authenticate using enterprise sign on with multi factor\n    Trust-&gt;&gt;Auditor: Authorize by role assignment marked as auditor\n\n    %% Step 2 - Manifest Verification\n    Auditor-&gt;&gt;Trust: Retrieve assurance manifest from trusted storage\n    Trust--&gt;&gt;Auditor: Provide manifest with signatures and timestamps\n    Auditor-&gt;&gt;Vendor: Confirm vendor approval signature\n    Auditor-&gt;&gt;Customer: Confirm customer approval signature\n    Auditor--&gt;&gt;Auditor: Verify manifest is current and represents agreed scope\n\n    %% Step 3 - Scope Mapping\n    Auditor-&gt;&gt;Auditor: Identify frameworks listed in manifest such as SOC two or ISO twenty seven thousand one\n    Auditor-&gt;&gt;Auditor: Load framework data into audit checklist tool\n    Auditor--&gt;&gt;Trust: Record mapping reference for traceability</code></pre> <p>Actors</p> <ul> <li>Auditor \u2013 Performs an independent review under defined trust conditions.  </li> <li>TrustCentre \u2013 Read-only portal/API exposing signed evidence.  </li> <li>Vendor &amp; Customer \u2013 Co-authors/co-signers of the Assurance Manifest.  </li> </ul> <p>Actions</p> <ol> <li> <p>Access Request </p> <ul> <li>Auditor receives read-only credentials to the TrustCentre portal or API.  </li> <li>Authentication via OIDC / SSO; authorization via policy-based roles (e.g., <code>role=auditor</code>).  </li> </ul> </li> <li> <p>Manifest Verification </p> <ul> <li>Auditor pulls the Assurance Manifest from the WORM OCI (TrustCentre).  </li> <li>Validates signature, timestamp, and multi-party approval (vendor + customer).  </li> <li>Confirms this is the current and agreed-upon version of the assurance scope.  </li> </ul> </li> <li> <p>Scope Mapping </p> <ul> <li>Auditor notes frameworks referenced in the manifest (e.g., SOC 2, ISO 27001, AI Bias).  </li> <li>Loads them into an audit checklist tool or GRC system for cross-referencing.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Least-Privilege Access Auditor operates with read-only, role-scoped permissions. Verified Scope Co-signed, current manifest is validated before any review. Framework Alignment Scope is mapped to recognized frameworks/controls for traceability. Immutable Source of Truth All scope references come from WORM-backed artifacts in TrustCentre."},{"location":"framework/workflows/assurance/#2-provenance-integrity-verification","title":"2) Provenance &amp; Integrity Verification","text":"<p>Confirm findings are legitimate.</p> Click to view <pre><code>sequenceDiagram\n    participant Auditor\n    participant Ledger as TrustCentre_Provenance_Ledger\n    participant Rekor as Transparency_Log_TSA\n    autonumber\n\n    %% Step 1 - Retrieve Provenance Attestations\n    Auditor-&gt;&gt;Ledger: Query provenance records for build and scan events\n    Ledger--&gt;&gt;Auditor: Return attestations with source commit id, container digest, toolchain id, and timestamp proof\n\n    %% Step 2 - Cryptographic Validation\n    Auditor-&gt;&gt;Auditor: Run local verification command using trust control tool\n    Auditor-&gt;&gt;Rekor: Request transparency inclusion confirmation\n    Rekor--&gt;&gt;Auditor: Provide log entry and timestamp authority record\n    Auditor-&gt;&gt;Auditor: Validate signatures match trusted keys and attestations match commit data\n\n    %% Step 3 - Cross Reference with Audit Ledger\n    Auditor-&gt;&gt;Ledger: Inspect linked audit ledger entries\n    Ledger--&gt;&gt;Auditor: Return event list and integrity data\n    Auditor-&gt;&gt;Auditor: Verify entry chain integrity and completeness using hash linking\n    Auditor-&gt;&gt;Auditor: Confirm time sequence is consistent and increasing\n    Auditor--&gt;&gt;Rekor: Report verification summary for archival</code></pre> <p>Actors</p> <ul> <li>Auditor \u2013 Verifies cryptographic provenance and integrity.  </li> <li>TrustCentre Provenance Ledger \u2013 Stores in-toto/SLSA attestations.  </li> <li>Rekor / TSA \u2013 Transparency log and timestamp authority.  </li> </ul> <p>Actions</p> <ol> <li> <p>Retrieve Provenance Attestations </p> <ul> <li>Auditor queries the Provenance Ledger (in-toto/SLSA) in TrustCentre.  </li> <li>Each attestation links a build/scan/analysis event to: source commit hash, container digest, toolchain ID, timestamp authority proof.  </li> </ul> </li> <li> <p>Cryptographic Validation </p> <ul> <li>Auditor uses the TrustCentre verification CLI: <code>trustctl verify --manifest manifest.yaml --rekor --oci --intoto</code> </li> <li>Verifies: Cosign signatures match trusted keys; Rekor inclusion proof is valid; in-toto attestations match commit hashes.  </li> </ul> </li> <li> <p>Cross-reference with Audit Ledger </p> <ul> <li>Auditor inspects Audit Ledger for:  </li> <li>Event integrity (entry_hash chain verification)  </li> <li>Completeness (no missing event IDs)  </li> <li>Consistent time ordering (monotonic timestamps)  </li> <li>Ledger verification is performed cryptographically using Merkle proofs.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description End-to-End Provenance Every artifact ties back to commits, toolchains, and timestamps. Cryptographic Integrity Independent verification via Cosign, Rekor, and in-toto. Complete Event History No gaps or ordering anomalies in ledger chains. Tamper Evidence Merkle proofs detect alteration attempts."},{"location":"framework/workflows/assurance/#3-review-of-assurance-evidence","title":"3) Review of Assurance Evidence","text":"<p>Review the audit ledger.</p> Click to view <pre><code>sequenceDiagram\n    participant Auditor\n    participant Registry\n    participant Ledger\n    autonumber\n\n    %% Step 1 - Artifact Inspection\n    Auditor-&gt;&gt;Registry: Browse evidence registry catalog\n    Registry--&gt;&gt;Auditor: List artifacts and metadata\n    Auditor-&gt;&gt;Registry: Download signed artifacts such as SARIF findings, AI reports, policy results, waiver documents, DeepEval metrics\n    Registry--&gt;&gt;Auditor: Return selected artifacts with basic details\n\n    %% Step 2 - Signature and Timestamp Validation\n    Auditor-&gt;&gt;Auditor: Verify signature chain using cosign keyless or threshold methods\n    Auditor-&gt;&gt;Auditor: Confirm timestamp proof per r f c three one six one\n    Auditor--&gt;&gt;Registry: Record validation outcome for the inspected set\n\n    %% Step 3 - AI Reasoning Traceability\n    Auditor-&gt;&gt;Auditor: Check AI output schema sequence then prompt then context then model then generated output then evaluation\n    Auditor-&gt;&gt;Ledger: Query hash records and evaluation scores linked to the artifacts\n    Ledger--&gt;&gt;Auditor: Provide hash references and score entries for traceability\n    Auditor--&gt;&gt;Registry: Note verified provenance and integrity for audit record</code></pre> <p>Actors</p> <ul> <li>Auditor \u2013 Examines signed evidence and AI reasoning traces.  </li> <li>WORM OCI Evidence Registry \u2013 Stores immutable artifacts.  </li> </ul> <p>Actions</p> <ol> <li> <p>Artifact Inspection </p> <ul> <li>Auditor navigates the WORM OCI Evidence Registry (e.g., <code>oci://trustcentre/org/product@sha256...</code>).  </li> <li>Downloads/queries signed artifacts: SARIF findings, AI assurance reports, policy evaluation results, signed waiver documents, DeepEval metrics.  </li> </ul> </li> <li> <p>Signature &amp; Timestamp Validation </p> <ul> <li>Verifies each artifact\u2019s signature chain (Cosign keyless or threshold).  </li> <li>Confirms RFC 3161 timestamp proofs.  </li> </ul> </li> <li> <p>AI Reasoning Traceability </p> <ul> <li>Checks AI outputs against their schema: Prompts \u2192 Context \u2192 Model \u2192 Generated Output \u2192 Evaluation.  </li> <li>Each step has a recorded hash and DeepEval score logged in the Audit Ledger.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Evidence Completeness All required artifacts are present and retrievable. Signed &amp; Time-Bound Valid signatures and timestamp proofs on each artifact. Explainable AI Reasoning steps are schema-valid, hashed, and auditable. Ledger Traceability Every artifact maps to ledger entries for confirmation."},{"location":"framework/workflows/assurance/#4-policy-compliance-verification","title":"4) Policy Compliance Verification","text":"<p>Confirm you are meeting your organizational standards.</p> Click to view <pre><code>sequenceDiagram\n    participant Auditor\n    participant Gate as Policy_Gate\n    participant Ledger\n    autonumber\n\n    %% Step 1 - Policy Mapping\n    Auditor-&gt;&gt;Auditor: Parse manifest policies section\n    Auditor-&gt;&gt;Auditor: Extract control id, test type, acceptance criteria\n    Auditor-&gt;&gt;Auditor: Example rules\\nno critical vulnerabilities means fail\\nbias under threshold means pass\n\n    %% Step 2 - Result Correlation\n    Auditor-&gt;&gt;Gate: Request evaluation summary for selected controls\n    Gate--&gt;&gt;Auditor: Return outcomes marked pass fail or waiver\n    Auditor-&gt;&gt;Ledger: Query policy results linked to the manifest version\n    Ledger--&gt;&gt;Auditor: Provide cryptographic links to evidence references\n\n    %% Step 3 - Human in the Loop Justifications\n    Auditor-&gt;&gt;Ledger: Retrieve signed waiver records for exceptions\n    Ledger--&gt;&gt;Auditor: Return reviewer identity signed time justification and policy link\n    Auditor--&gt;&gt;Auditor: Confirm controls and acceptance criteria were enforced</code></pre> <p>Actors</p> <ul> <li>Auditor \u2013 Confirms controls and acceptance criteria were enforced.  </li> <li>Policy Gate \u2013 Evaluates findings vs Manifest criteria.  </li> </ul> <p>Actions</p> <ol> <li> <p>Policy Mapping </p> <ul> <li>Auditor parses the manifest\u2019s <code>policies:</code> section.  </li> <li>Each policy defines <code>control_id</code>, <code>test_type</code>, and <code>acceptance_criteria</code> (e.g., No Critical CVEs, bias &lt; 0.05).  </li> </ul> </li> <li> <p>Result Correlation </p> <ul> <li>Auditor queries Policy Gate results in the ledger: <code>trustctl query policy --id SEC-01 --manifest manifest:v1.2</code> </li> <li>Each control\u2019s outcome (<code>pass</code>, <code>fail</code>, <code>waiver</code>) is cryptographically linked to evidence URIs.  </li> </ul> </li> <li> <p>Human-in-the-Loop Justifications </p> <ul> <li>Auditor checks signed waiver records for any exceptions: reviewer identity (signed), timestamp, justification, policy linkage.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Control-Level Traceability Each policy outcome references concrete evidence artifacts. Objective Criteria Pass/fail thresholds from the manifest are consistently applied. Accountable Exceptions Waivers are signed, justified, and auditable. Policy-to-Evidence Binding Outcomes cryptographically link back to artifacts and signers."},{"location":"framework/workflows/assurance/#5-reconstructing-the-assurance-run","title":"5) Reconstructing the Assurance Run","text":"<p>Replay the evidence chain for posterity.</p> Click to view <pre><code>sequenceDiagram\n    participant Auditor\n    participant Ledger as Audit_Ledger\n    autonumber\n\n    %% Step 1 - Run Replay\n    Auditor-&gt;&gt;Ledger: Request reconstruction of a historical assurance run\n    Ledger--&gt;&gt;Auditor: Provide code version, tools, findings, reasoning, and enforced policies\n    Auditor-&gt;&gt;Auditor: Rebuild historical environment and analysis flow\n\n    %% Step 2 - Audit Evidence Chain\n    Auditor-&gt;&gt;Auditor: Produce evidence lineage sequence\\nManifest to Provenance to Scan to Normalization to AI Reasoning to Policy Gate to Signed Report\n    Auditor-&gt;&gt;Auditor: Verify each link includes matching hash and signature pair\n\n    %% Step 3 - Compare to Current State\n    Auditor-&gt;&gt;Ledger: Retrieve current state snapshot for the same system\n    Ledger--&gt;&gt;Auditor: Return recent records and digests\n    Auditor-&gt;&gt;Auditor: Compare historical and current evidence sets\n    Auditor-&gt;&gt;Auditor: Identify drift, unapproved changes, or missing attestations\n    Auditor--&gt;&gt;Ledger: Record comparison summary for forensics archive</code></pre> <p>Actors</p> <ul> <li>Auditor \u2013 Replays historical runs for forensics and regulatory assurance.  </li> <li>Audit Ledger \u2013 Provides event sequences and hashes.  </li> </ul> <p>Actions</p> <ol> <li> <p>Run Replay </p> <ul> <li>Using ledger data, reconstructs an entire historical run (code version, tools, findings, AI reasoning, policies enforced).  </li> </ul> </li> <li> <p>Audit Evidence Chain </p> <ul> <li>Produces the lineage: <code>Manifest \u2192 Provenance \u2192 Scan \u2192 Normalization \u2192 AI Reasoning \u2192 Policy Gate \u2192 Signed Report</code> </li> <li>Each arrow is backed by a hash + signature pair.  </li> </ul> </li> <li> <p>Compare to Current State </p> <ul> <li>Compares replayed evidence to the current system snapshot to detect drift, unapproved changes, or missing attestations.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Forensic Reproduction Entire runs can be replayed exactly from immutable records. Continuity &amp; Consistency Differences vs current system are detectable and explainable. Chain-of-Custody Proof Every stage is linked and signed across the pipeline. Regulatory Readiness Replay artifacts satisfy regulator requests efficiently."},{"location":"framework/workflows/assurance/#6-report-generation-attestation","title":"6) Report Generation &amp; Attestation","text":"<p>Create reports and share the findings.</p> Click to view <pre><code>sequenceDiagram\n    participant Auditor\n    participant Centre as TrustCentre\n    participant Ledger as Audit_Ledger\n    autonumber\n\n    %% Step 1 - Compile Findings\n    Auditor-&gt;&gt;Auditor: Summarize verified controls and exceptions\n    Auditor-&gt;&gt;Auditor: Include waiver notes, confidence metrics, and digest list\n    Auditor--&gt;&gt;Auditor: Prepare data set for attestation report\n\n    %% Step 2 - Generate Audit Attestation\n    Auditor-&gt;&gt;Auditor: Create digitally signed assurance attestation report\n    Auditor-&gt;&gt;Auditor: Reference manifest, artifact hashes, and transparency proofs\n    Auditor--&gt;&gt;Auditor: Store report within the auditor managed repository\n\n    %% Step 3 - Anchor to TrustCentre\n    Auditor-&gt;&gt;Centre: Submit signed attestation for anchoring\n    Centre-&gt;&gt;Ledger: Record attestation reference and timestamp\n    Ledger--&gt;&gt;Centre: Return confirmation log entry\n    Centre--&gt;&gt;Auditor: Provide verification link and anchored record summary</code></pre> <p>Actors</p> <ul> <li>Auditor \u2013 Issues a signed Assurance Attestation Report (AAR).  </li> <li>TrustCentre \u2013 Anchors and exposes the attestation for verification.  </li> </ul> <p>Actions</p> <ol> <li> <p>Compile Findings </p> <ul> <li>Summarizes: verified controls, exceptions/waivers, confidence metrics (DeepEval, AI consistency), digest list.  </li> </ul> </li> <li> <p>Generate Audit Attestation </p> <ul> <li>Produces a digitally signed AAR referencing manifest, artifact hashes, Rekor proofs (stored in auditor\u2019s OCI repo).  </li> </ul> </li> <li> <p>Anchor to TrustCentre </p> <ul> <li>Submits AAR to the TrustCentre Transparency Log; Rekor log ID and timestamp appended to the Audit Ledger.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Signed Auditor Statement Independent attestation is cryptographically verifiable. Discoverable Proof AAR visible via Transparency Log for customers/regulators. Tight Ledger Integration Attestation linked to vendor\u2019s immutable audit history. Portable Verification Proof can be verified without trusting vendor infrastructure."},{"location":"framework/workflows/assurance/#7-continuous-monitoring-trust-renewal","title":"7) Continuous Monitoring &amp; Trust Renewal","text":"<p>Monitor the system for assurance events.</p> Click to view <pre><code>sequenceDiagram\n    participant Auditor\n    participant Centre as TrustCentre\n    participant Ledger\n    autonumber\n\n    %% Step 1 - Scheduled Audit Hooks\n    Auditor-&gt;&gt;Centre: Subscribe to assurance event feed using webhook\n    Centre--&gt;&gt;Auditor: Confirm subscription for continuous updates\n    Centre-&gt;&gt;Auditor: Send notification for each new assurance run\n    Auditor-&gt;&gt;Ledger: Verify ledger root hash automatically\n    Ledger--&gt;&gt;Auditor: Return validation result\n\n    %% Step 2 - Trust Drift Detection\n    Centre-&gt;&gt;Auditor: Alert when manifest or signing key changes detected\n    Auditor-&gt;&gt;Ledger: Request difference report since last attestation\n    Ledger--&gt;&gt;Auditor: Provide evidence change summary and updated hashes\n    Auditor-&gt;&gt;Auditor: Review alert and confirm trust drift analysis\n\n    %% Step 3 - Periodic Trust Reanchoring\n    Auditor-&gt;&gt;Centre: Initiate scheduled reverification cycle\n    Centre-&gt;&gt;Ledger: Supply current ledger roots and proof references\n    Ledger--&gt;&gt;Auditor: Return verification data set for archival\n    Auditor-&gt;&gt;Auditor: Validate roots and transparency proofs for preservation</code></pre> <p>Actors</p> <ul> <li>Auditor \u2013 Subscribes to ongoing assurance signals.  </li> <li>TrustCentre \u2013 Emits event feeds and ledger roots for verification.  </li> </ul> <p>Actions</p> <ol> <li> <p>Scheduled Audit Hooks </p> <ul> <li>Auditor subscribes to assurance event feeds (webhooks).  </li> <li>Each new run\u2019s ledger root hash is verified automatically.  </li> </ul> </li> <li> <p>Trust Drift Detection </p> <ul> <li>Alerts on manifest or signing key changes.  </li> <li>Ledger diff reports show evidence changes since last attestation.  </li> </ul> </li> <li> <p>Periodic Trust Re-Anchoring </p> <ul> <li>Every 30/90 days, auditor re-verifies ledger roots and Rekor proofs for long-term preservation.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Always-On Assurance Posture is continuous, not annual. Early-Warning Signals Drift/key-rotation alerts trigger proactive reviews. Durable Verifiability Regular re-anchoring maintains long-term integrity. Low-Touch Governance Automation reduces manual overhead while increasing trust."},{"location":"framework/workflows/assurance/#end-state","title":"End State","text":"<p>Desired Outcomes</p> Outcome Description Machine-Readable Attestation Auditor issues a signed, verifiable report of control outcomes. Cryptographically Anchored Integrity proven via Sigstore, Rekor, and Audit Ledger. Zero Additional Trust Assumptions Verification possible without the vendor\u2019s pipeline. Repeatable &amp; Replayable Future audits can replay runs and confirm assurance continuity. <p>Auditor Value Summary</p> Dimension Old Way New Continuous Assurance Way Evidence Validation Manual screenshots, spreadsheets Cryptographic proof chain (Rekor, OCI, Ledger) Scope Control Static compliance matrix Live manifest defining required proofs Audit Cadence Reactive, once a year Continuous, trust-anchored visibility Independence Based on vendor statements Verified against immutable TrustCentre data Non-Repudiation None Built-in with Sigstore, WORM, TSA, KMS"},{"location":"framework/workflows/construction/","title":"Construction Use Case","text":"<p>This use case is a working-in-progress example of how the assurance framework and logic can be leveraged as part of a non-IT or cyber-physical system. While we are not necessarily building this out, the goal is to ensure that our framework can map to real-world domains where safety, integrity, and verifiable compliance are critical. The same \u201cContinuous Assurance\u201d framework that validates digital systems can validate physical systems like bridges or buildings. The only change is the domain of metrics but the principles of traceability, immutability, and verifiable policy alignment remain identical.</p>"},{"location":"framework/workflows/construction/#0-pre-construction-assurance-design-planning","title":"0) Pre-Construction Assurance (Design &amp; Planning)","text":"<ul> <li>Validate that the Assurance Manifest matches design specifications and applicable regulatory codes (CSA, ASTM, ISO 9001).  </li> <li>Require signed attestations from design engineers, material suppliers, and site supervisors before construction begins.  </li> <li>Run simulated probes in BIM or digital twin environments to verify that thresholds and sensor configurations are adequate.  </li> <li>Store this as a baseline manifest (<code>v0.0</code>) in the TrustCentre for future comparison and drift detection.  </li> </ul>"},{"location":"framework/workflows/construction/#1-goal","title":"1) Goal","text":"<p>Continuously test and verify that construction projects, materials, and subcontractor processes remain safe, compliant, and within performance thresholds, producing signed, immutable evidence of quality at every phase.</p>"},{"location":"framework/workflows/construction/#2-key-actors","title":"2) Key Actors","text":"Role Construction Equivalent Function System Under Test (SUT) Project Site, Structural Section, or Subsystem (HVAC, electrical, concrete pour) The entity being verified Assurance Pipeline Construction QA/QC Process + Digital Twin Sensors Continuous data collection and analysis TrustCentre Immutable Evidence Repository (Digital Twin Ledger / BIM Integration) Stores signed reports, inspections, IoT telemetry AI Reasoner Predictive Analytics / Compliance Checker Interprets data, identifies anomalies, and verifies specs Auditors / Inspectors Building Officials, Safety Officers, Owner\u2019s Reps Verify evidence and sign off on assurance milestones"},{"location":"framework/workflows/construction/#3-assurance-manifest-construction-equivalent","title":"3) Assurance Manifest (Construction Equivalent)","text":"<p>Defines what makes the project compliant and safe.</p> <pre><code>project:\n  id: \"highway-bridge-segment-42\"\n  version: \"2025.10.10\"\n  phase: \"Foundation Pour\"\n  contractor: \"Steel &amp; Stone Ltd.\"\n  evaluation:\n    schedule: \"R/1D\"                 # daily checks\n    datasets:\n      - name: \"ConcreteSampleTests\"\n        kind: \"material_quality\"\n        source: \"oci://trustcentre/lab/concrete_results@sha256:...\"\n      - name: \"WorkerSafetyIncidents\"\n        kind: \"safety\"\n        source: \"oci://trustcentre/site/safety@sha256:...\"\n      - name: \"EnvironmentalSensors\"\n        kind: \"environmental\"\n        source: \"oci://trustcentre/iot/environment@sha256:...\"\n    metrics:\n      material_quality:\n        compressive_strength_min: 30  # MPa\n        slump_range: [75, 125]        # mm\n      safety:\n        lost_time_injuries: 0\n        near_miss_rate_max: 0.02\n      environmental:\n        vibration_threshold_mm_s: 10\n        noise_threshold_db: 85\n    gates:\n      block_on_fail: [\"safety\", \"material_quality\"]\n      warn_on_fail: [\"environmental\"]\n    attestations:\n      sign_with: \"cosign://keys/qa-inspector\"\n      publish_to: \"oci://trustcentre/org/assurance\"\n</code></pre>"},{"location":"framework/workflows/construction/#4-assurance-flow","title":"4) Assurance Flow","text":"Assurance Flow (Safe Sequence) <pre><code>sequenceDiagram\n    participant SUT as System_Under_Test\n    participant TC as TrustCentre\n    participant PROBE as Scheduled_Probes\n    participant NORM as Normalization\n    participant AI as AI_Reasoner\n    participant HUM as Human_Review\n    participant GATE as Sign_Publish_Service\n    participant LED as Audit_Ledger\n    autonumber\n\n    %% Registration\n    SUT-&gt;&gt;TC: Register subsystem or site with identifiers and certificates\n    TC--&gt;&gt;SUT: Return registration record\n\n    %% Data Collection\n    PROBE-&gt;&gt;SUT: Collect daily readings for strength, temperature, humidity, and vibration\n    SUT--&gt;&gt;PROBE: Provide sensor data, safety logs, equipment telemetry, and environment values\n    PROBE-&gt;&gt;NORM: Send collected data for processing\n\n    %% Normalization\n    NORM-&gt;&gt;NORM: Convert results into standard format\n    NORM-&gt;&gt;NORM: Remove duplicates and anomalies for consistency\n\n    %% Evaluation\n    NORM-&gt;&gt;AI: Provide normalized dataset for analysis\n    AI-&gt;&gt;AI: Compare values against manifest thresholds and detect drift\n    AI-&gt;&gt;AI: Check strength threshold satisfied then mark as pass\n    AI-&gt;&gt;AI: Check for safety incidents then mark as block\n    AI-&gt;&gt;AI: Check noise level greater than eighty five decibel then mark as warn\n    AI--&gt;&gt;HUM: Send flagged anomalies for review\n\n    %% Human Review\n    HUM-&gt;&gt;HUM: Review anomalies and add comments or waivers or retest plans\n    HUM--&gt;&gt;AI: Return human decisions and notes\n\n    %% Signed Assurance Report\n    AI-&gt;&gt;GATE: Create final assurance report with material, safety, and environmental results\n    GATE-&gt;&gt;GATE: Sign report using trusted signing service\n    GATE-&gt;&gt;TC: Upload signed report to immutable registry\n    GATE-&gt;&gt;LED: Log digest signer timestamp and metadata\n    GATE--&gt;&gt;SUT: Provide access reference for report</code></pre>"},{"location":"framework/workflows/construction/#41-registration","title":"4.1 Registration","text":"<ul> <li>Each subsystem or site section is registered as a \u201cSystem Under Test\u201d in TrustCentre.  </li> <li>Includes BIM element IDs, geographic coordinates, and subcontractor certifications.</li> </ul>"},{"location":"framework/workflows/construction/#42-data-collection-scheduled-probes","title":"4.2 Data Collection (Scheduled Probes)","text":"<ul> <li>IoT sensors, drones, and lab data streams feed daily probes:  </li> <li>Concrete strength tests, curing temperature, humidity, vibration levels.  </li> <li>Safety incident logs, worker attendance, equipment telemetry.  </li> <li>Environmental readings (noise, dust, CO\u2082).</li> </ul>"},{"location":"framework/workflows/construction/#43-normalization","title":"4.3 Normalization","text":"<ul> <li>All sensor and lab results normalized into a SARIF-like format.  </li> <li>Deduplication and anomaly removal for consistent evaluation.</li> </ul>"},{"location":"framework/workflows/construction/#44-evaluation-policy-comparison","title":"4.4 Evaluation (Policy Comparison)","text":"<ul> <li>AI Reasoner compares results to Manifest thresholds and detects drift trends.  </li> <li>Example checks:  </li> <li>Compressive strength \u2265 30 MPa \u2192 Pass  </li> <li>Any safety incident \u2192 Block  </li> <li>Noise &gt; 85 dB \u2192 Warn  </li> </ul>"},{"location":"framework/workflows/construction/#45-human-in-the-loop-review","title":"4.5 Human-in-the-Loop Review","text":"<ul> <li>Engineers or inspectors review AI-flagged anomalies.  </li> <li>Add comments or waivers (\u201callowed due to environmental conditions; retest scheduled\u201d).  </li> </ul>"},{"location":"framework/workflows/construction/#46-signed-construction-assurance-report","title":"4.6 Signed Construction Assurance Report","text":"<ul> <li>Aggregates results + human notes into a report that includes:  </li> <li>Material, safety, and environmental compliance.  </li> <li>Signed (Cosign/KMS) and pushed to TrustCentre OCI.  </li> <li>Logged in the Audit Ledger for non-repudiation.</li> </ul>"},{"location":"framework/workflows/construction/#5-example-report-summary-json","title":"5) Example Report (Summary JSON)","text":"<pre><code>{\n  \"report_id\": \"bridge-42-foundation-2025-10-10\",\n  \"section\": \"Foundation Pour\",\n  \"metrics\": {\n    \"material_quality\": { \"strength_mpa\": 32.4, \"slump_mm\": 102, \"status\": \"pass\" },\n    \"safety\": { \"lt_injuries\": 0, \"near_miss_rate\": 0.01, \"status\": \"pass\" },\n    \"environmental\": { \"noise_db\": 88, \"status\": \"warn\" }\n  },\n  \"policy_verdict\": { \"overall\": \"pass_with_warning\" },\n  \"signed_by\": \"qa_inspector@steelandstone.com\",\n  \"rekor_log_id\": \"log:8832\",\n  \"timestamp\": \"2025-10-10T19:45:00Z\"\n}\n</code></pre>"},{"location":"framework/workflows/construction/#6-ai-reasoner-extensions-for-construction","title":"6) AI Reasoner Extensions for Construction","text":"Function Example Behavior Drift Detection Detects sensor degradation or slump deviation suggesting supply issues. Predictive Risk Forecasting Predicts curing temperature violations or schedule slippage. Fairness / Safety Analytics Ensures equal safety compliance across subcontractors or shifts. Policy Alignment Reasoning Maps construction spec IDs to manifest rules automatically. Explainable Root Cause Reports \u201cSlump deviation due to humidity 80%; suggest admixture adjustment.\u201d"},{"location":"framework/workflows/construction/#7-digital-evidence-chain","title":"7) Digital Evidence Chain","text":"<p>Every result \u2014 lab report, safety log, AI analysis, human approval \u2014 is:</p> <ul> <li>Signed &amp; Timestamped: via Sigstore or PKI.  </li> <li>Anchored in Rekor: for public verifiability.  </li> <li>Stored in WORM OCI: immutable evidence retention.  </li> <li>Linked to BIM / Digital Twin: each element references its evidence bundle.  </li> <li>Auditable: regulators can replay the full evidence chain.</li> </ul>"},{"location":"framework/workflows/construction/#8-integration-opportunities","title":"8) Integration Opportunities","text":"Layer Example Integration Pipeline (Data Ingestion) Autodesk Construction Cloud, Procore, Trimble Connect, IoT gateways AI Reasoner Custom models for safety risk prediction and material drift TrustCentre / Ledger immudb or AWS QLDB for immutable ledger, OCI registry for evidence Visualization PowerBI / Grafana overlayed on BIM model Notifications Slack/Teams integration for compliance alerts Regulatory Compliance Integration with building codes, ISO QA records, OSHA/CSA safety compliance Governance &amp; Audit Export of assurance evidence to shared TrustCentre nodes for regulators"},{"location":"framework/workflows/construction/#9-benefits-to-the-construction-industry","title":"9) Benefits to the Construction Industry","text":"Benefit Description Continuous Assurance Real-time verification of quality &amp; safety, not just milestone inspections. Immutable Evidence Digitally signed, tamper-proof QA/QC records. Predictive Prevention Detect drift or degradation early to prevent rework. Trust Exchange Share verifiable assurance data with owners and regulators. Cross-Project Intelligence AI Reasoner learns patterns across projects to optimize QA/QC policies."},{"location":"framework/workflows/construction/#10-future-extensions","title":"10) Future Extensions","text":"<ol> <li>Supply Chain Material Assurance </li> <li>Link suppliers (cement, steel) to TrustCentre; every batch has a signed material manifest.  </li> <li> <p>Enables ESG provenance tracking.  </p> </li> <li> <p>AI + Digital Twin Synchronization </p> </li> <li> <p>Connect assurance reports to live digital twin models; visualize compliance zones in 3D.  </p> </li> <li> <p>Zero-Trust Construction Certification </p> </li> <li> <p>Regulators verify compliance proofs directly in TrustCentre instead of manual logs.  </p> </li> <li> <p>Predictive Maintenance Integration </p> </li> <li>Extend assurance to post-construction operational monitoring (bridges, HVAC, etc.).  </li> </ol>"},{"location":"framework/workflows/construction/#11-continuous-improvement-loop","title":"11) Continuous Improvement Loop","text":"<ul> <li>Each project contributes anonymized data back into a shared Assurance Knowledge Graph.  </li> <li>The AI Reasoner updates manifest thresholds and risk models using historical trends.  </li> <li>Policy recommendations are proposed for review and signed into new manifest versions.  </li> <li>Human review committees ensure that automation remains explainable and auditable.  </li> </ul>"},{"location":"framework/workflows/construction/#12-testing-validation-framework","title":"12) Testing &amp; Validation Framework","text":"<ul> <li>Simulation Tests: Verify sensors and manifest logic trigger correctly under test conditions.  </li> <li>Drift Calibration Tests: Confirm sensor accuracy and calibration integrity.  </li> <li>Human-in-the-Loop Testing: Random audits of AI-flagged events with dual approval.  </li> <li>End-to-End Replay: Re-run historical data to ensure deterministic reproducibility.  </li> </ul>"},{"location":"framework/workflows/engineer/","title":"Security Engineer","text":"<p>For this particular set of workflows, we will focus on the activities and decision processes of a Security Engineer. These workflows illustrate how the engineer engages with assurance mechanisms throughout the lifecycle of evidence capture, validation, and analysis.  To provide a complete picture, these interactions are presented within the context of an a conversational chatbot interface designed to guide, validate, and document assurance activities in real time. The chatbot acts as both a facilitator and a verifier, ensuring that each action taken by the Security Engineer is traceable, policy-aligned, and cryptographically verifiable.</p> <p>By modeling these workflows through a chat-based interaction, we can highlight how automation, provenance, and AI reasoning converge to enhance trust, transparency, and accountability in modern security assurance operations.</p>"},{"location":"framework/workflows/engineer/#1-session-initialization-context-bootstrapping","title":"1) Session Initialization: Context Bootstrapping","text":"<p>Ensure authrozied people start session with verified outputs.</p> Click to view <pre><code>sequenceDiagram\n    participant ENG as Security_Engineer\n    participant AGENT as Assurance_Chat_Agent\n    participant TC as TrustCentre\n    autonumber\n\n    %% Engineer Authenticates\n    ENG-&gt;&gt;AGENT: Authenticate via OIDC / SSO (with MFA)\n    AGENT-&gt;&gt;AGENT: Bind session to identity and key pair\n    AGENT-&gt;&gt;AGENT: Sign and timestamp all prompts/responses\n    Note right of AGENT: Secure session established for trusted reasoning\n\n    %% Session Context Retrieval\n    AGENT-&gt;&gt;TC: Retrieve Assurance Manifest, scan results, AI outputs, ledger entries\n    TC--&gt;&gt;AGENT: Return signed data and metadata\n    AGENT-&gt;&gt;ENG: Display context summary&lt;br/&gt;System X (build 2025.10.10)&lt;br/&gt;78 findings, 4 waivers pending\n\n    %% Trust Validation\n    AGENT-&gt;&gt;TC: Verify OCI signatures and Rekor entries\n    TC--&gt;&gt;AGENT: Provide verification status\n    AGENT--&gt;&gt;ENG: Confirm provenance validated before reasoning</code></pre> <p>Actors</p> <ul> <li>Security Engineer \u2013 Authenticates, queries, and reviews assurance context.  </li> <li>Assurance Chat Agent \u2013 Verifies provenance and orchestrates retrieval/reasoning.  </li> <li>TrustCentre \u2013 Source of signed manifests, ledger entries, and evidence.  </li> </ul> <p>Actions</p> <ol> <li> <p>Engineer Authenticates </p> <ul> <li>Logs in via OIDC / enterprise SSO (with MFA) to the Assurance Chat portal.  </li> <li>Chat session is bound to the engineer\u2019s identity and key pair \u2014 all prompts/responses are signed and timestamped.  </li> </ul> </li> <li> <p>Session Context Retrieval </p> <ul> <li>Agent auto-loads the current Assurance Manifest, latest scan results and AI reasoning outputs, and Ledger entries for the latest run.  </li> <li>Displays a contextual greeting:   \u201cYou\u2019re reviewing System X (build 2025.10.10). 78 findings detected, 4 waivers pending review.\u201d  </li> </ul> </li> <li> <p>Trust Validation </p> <ul> <li>Before any reasoning, the agent verifies OCI signatures and Rekor entries.  </li> <li>The engineer is never reasoning on untrusted or unsigned data.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Verified Session Context All artifacts loaded for the session are signed, timestamped, and current. Identity-Bound Interactions Each query and response is bound to the engineer\u2019s identity and key. Provenance-First Workflow Reasoning only occurs on cryptographically verified inputs. Frictionless Kickoff The engineer starts with an actionable, trustworthy summary."},{"location":"framework/workflows/engineer/#2-exploratory-querying-analysis","title":"2) Exploratory Querying &amp; Analysis","text":"<p>Explore and analyze the threat surface in detail.</p> Click to view <pre><code>sequenceDiagram\n    participant ENG as Security_Engineer\n    participant AGENT as Assurance_Chat_Agent\n    participant RET as Retriever\n    participant LED as Ledger\n    autonumber\n\n    %% Step 1 - Exploration\n    ENG-&gt;&gt;AGENT: Ask for high-severity issues in auth service\n    AGENT-&gt;&gt;RET: Query retriever index (BM25 + embeddings)\n    AGENT-&gt;&gt;LED: Get recent ledger changes\n    AGENT--&gt;&gt;ENG: Return summarized findings\n\n    %% Step 2 - Code Context\n    ENG-&gt;&gt;AGENT: Show code and fix for hardcoded secret\n    AGENT-&gt;&gt;RET: Fetch code snippet and related policy rule\n    AGENT--&gt;&gt;ENG: Provide summary and remediation advice\n\n    %% Step 3 - Cross-System Reasoning\n    ENG-&gt;&gt;AGENT: Check if issue appeared before\n    AGENT-&gt;&gt;LED: Search historical records by fingerprint\n    AGENT--&gt;&gt;ENG: Reply with occurrence history and waiver reason</code></pre> <p>Actors</p> <ul> <li>Security Engineer \u2013 Explores, filters, and inspects findings.  </li> <li>Assurance Chat Agent \u2013 Queries Retriever index (BM25 + Embeddings), Audit Ledger, and AI Reasoning Memory.  </li> </ul> <p>Actions</p> <ol> <li> <p>Natural Language Exploration </p> <ul> <li>Engineer asks: \u201cShow me all high-severity vulnerabilities in the authentication microservice since the last patch.\u201d  </li> <li>Agent queries retrievers, ledger changes since last run, and prior AI recommendations.  </li> <li>Response example: <code>3 findings detected:</code> <code>\u2022 CVE-2024-5832 in auth.py:142 \u2013 Token reuse vulnerability.</code> <code>\u2022 Hardcoded secret in jwt_manager.py \u2013 found via OpenGrep.</code> <code>\u2022 Dependency outdated (Flask 2.0.3 &lt; 3.0.0) \u2013 known exploit path.</code> </li> </ul> </li> <li> <p>Code Context Summarization </p> <ul> <li>Engineer: \u201cShow the code context around the hardcoded secret and a recommended fix.\u201d  </li> <li>Agent retrieves function-level snippet from RAG memory and merges it with the policy rule on secret rotation; emits a signed contextual explanation.  </li> </ul> </li> <li> <p>Cross-System Reasoning </p> <ul> <li>Engineer: \u201cDid this issue appear in previous builds?\u201d  </li> <li>Agent searches historical ledger, matches fingerprints, and replies:   \u201cFirst seen 2025.09.12, waived once, reintroduced by commit <code>6d2f\u2026</code>. Waiver reason: legacy configuration handling.\u201d  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Conversational Discovery Natural-language queries reliably retrieve signed findings and context. Context-Rich Summaries Explanations include code, policy, and prior decisions. History-Aware Insights Fingerprint matching reveals regressions and waiver lineage. Signed Analytical Responses Explanations are emitted as verifiable artifacts."},{"location":"framework/workflows/engineer/#3-deep-reasoning-threat-simulation","title":"3) Deep Reasoning &amp; Threat Simulation","text":"<p>Run simulations to see what security defects might exist.</p> Click to view <pre><code>sequenceDiagram\n    participant Engineer\n    participant Agent\n    autonumber\n\n    %% Step 1 - Exploitability Simulation\n    Engineer-&gt;&gt;Agent: Request simulation for JWT reuse and hardcoded secret chain\n    Agent-&gt;&gt;Agent: Retrieve related code and dependency graph\n    Agent-&gt;&gt;Agent: Build attack chain hypothesis in three stages\n    Agent--&gt;&gt;Engineer: Run scenario\n    Agent-&gt;&gt;Agent: Sign and store threat scenario artifact\n\n    %% Step 2 - Dynamic Querying\n    Engineer-&gt;&gt;Agent: Run analysis assuming pull request two eight four merged\n    Agent-&gt;&gt;Agent: Collect code changes and update retriever data\n    Agent-&gt;&gt;Agent: Recalculate and compare new risk level\n    Agent--&gt;&gt;Engineer: Provide updated scenario with reduced risk summary</code></pre> <p>Actors</p> <ul> <li>Security Engineer \u2013 Requests simulations and what-if analysis.  </li> <li>Assurance Chat Agent \u2013 Performs fusion retrieval and produces signed Threat Scenario artifacts.  </li> </ul> <p>Actions</p> <ol> <li> <p>Exploitability Simulation </p> <ul> <li>Engineer: \u201cReason through the exploitability if JWT reuse and a hardcoded secret are chained.\u201d  </li> <li>Agent retrieves related code and dependency graphs, builds an attack-chain hypothesis: <code>1) Secret exfil from jwt_manager.py \u2192 2) Token forgery (CWE-345) \u2192 3) Bypass via /auth/refresh.</code> <code>Risk: Critical | EPSS 0.93 | CVSSv3 9.1</code> </li> <li>Output is signed as a Threat Scenario Artifact.  </li> </ul> </li> <li> <p>Dynamic Querying </p> <ul> <li>Engineer: \u201cRe-run assuming PR #284 is merged.\u201d  </li> <li>Agent fetches diffs, updates embeddings, re-evaluates, and reports risk reduction deltas.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Actionable Attack Paths Simulations describe credible, evidence-linked exploit chains. What-If Reruns Proposed fixes can be tested virtually against current evidence. Quantified Risk Scenarios include EPSS/CVSS and confidence indicators. Signed Scenarios Threat reasoning is preserved as immutable, replayable artifacts."},{"location":"framework/workflows/engineer/#4-ai-augmented-root-cause-analysis","title":"4) AI-Augmented Root Cause Analysis","text":"<p>Chat to root-cause.</p> Click to view <pre><code>sequenceDiagram\n    participant Engineer\n    participant Agent\n    autonumber\n\n    %% Causal Reasoning\n    Engineer-&gt;&gt;Agent: Request root causes for recurring credential issues\n    Agent-&gt;&gt;Agent: Cluster findings by category including CWE seven nine eight and CWE five two two\n    Agent--&gt;&gt;Engineer: Common root causes\\nInconsistent secret handling\\nLack of central key management\\nLinting overrides\n    Agent--&gt;&gt;Engineer: Recommended controls\\nEnforce centralized key management\\nPresubmit secret checks with static scanning\n\n    %% Auto Enrichment\n    Engineer-&gt;&gt;Agent: Add policy and metric context\n    Agent-&gt;&gt;Agent: Attach manifest control id SEC zero eight\n    Agent-&gt;&gt;Agent: Include recent MTTA metrics and ledger identifiers for traceability\n    Agent--&gt;&gt;Engineer: Return mapped controls and metrics with traceability summary</code></pre> <p>Actors</p> <ul> <li>Security Engineer \u2013 Seeks systemic contributors and controls.  </li> <li>Assurance Chat Agent \u2013 Clusters findings and maps to policies/metrics.  </li> </ul> <p>Actions</p> <ol> <li> <p>Causal Reasoning </p> <ul> <li>Engineer: \u201cRoot causes for recurring credential issues?\u201d  </li> <li>Agent clusters CWE-798 / CWE-522 findings, producing: <code>Common Root Causes:</code> <code>\u2022 Inconsistent secret handling</code> <code>\u2022 Lack of central KMS enforcement</code> <code>\u2022 Linting overrides</code> <code>Recommended Controls:</code> <code>\u2022 Enforce centralized KMS</code> <code>\u2022 Presubmit OpenGrep secret checks</code> </li> </ul> </li> <li> <p>Auto-Enrichment </p> <ul> <li>Adds Manifest control ID (SEC-08), recent MTTA metrics, and relevant ledger IDs for traceability.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Systemic Insight Patterns across services surface shared weaknesses. Policy-Linked Guidance Recommendations reference concrete controls and metrics. Traceable Analytics Root-cause outputs cite ledger events and artifacts. Prioritized Remediation Focus shifts from symptoms to durable controls."},{"location":"framework/workflows/engineer/#5-generating-signed-findings-evidence","title":"5) Generating Signed Findings &amp; Evidence","text":"<p>Review verified artifacts and findings.</p> Click to view <pre><code>sequenceDiagram\n    participant Engineer\n    participant Agent\n    participant Ledger\n    participant OCI\n    participant Manifest\n    autonumber\n\n    %% 1) Engineer Promotes Insight\n    Engineer-&gt;&gt;Agent: Click record as insight\n    Agent-&gt;&gt;Agent: Format analysis as JSON using insight schema\n    Agent-&gt;&gt;Agent: Sign with OIDC identity and Cosign\n    Agent-&gt;&gt;Ledger: Record analysis event\n    Ledger--&gt;&gt;Agent: Return event reference\n\n    %% 2) AI Creates Evidence Artifact\n    Agent-&gt;&gt;Agent: Package transcript and context references\n    Agent-&gt;&gt;Agent: Include reasoning trace and DeepEval metrics\n    Agent-&gt;&gt;OCI: Seal as versioned artifact in WORM OCI\n    OCI--&gt;&gt;Agent: Return artifact reference and digest\n\n    %% 3) Link Back to Assurance Manifest\n    Agent-&gt;&gt;Manifest: Add extended evidence entry with artifact digest\n    Manifest--&gt;&gt;Agent: Confirm manifest updated\n    Agent--&gt;&gt;Engineer: Provide evidence reference and manifest update summary</code></pre> <p>Actors</p> <ul> <li>Security Engineer \u2013 Promotes insights to evidence.  </li> <li>Assurance Chat Agent \u2013 Packages and signs analysis; updates ledger and manifest links.  </li> </ul> <p>Actions</p> <ol> <li> <p>Engineer Promotes Insight </p> <ul> <li>Clicks Record as Insight.  </li> <li>Agent formats analysis as JSON (<code>/insight</code> schema), signs it (OIDC + Cosign), and records an Analysis Event in the Audit Ledger.  </li> </ul> </li> <li> <p>AI Creates Evidence Artifact </p> <ul> <li>Packages transcript, context refs (findings, code, ledger IDs), LLM reasoning trace, and DeepEval metrics.  </li> <li>Seals to WORM OCI as a versioned artifact.  </li> </ul> </li> <li> <p>Link Back to Assurance Manifest </p> <ul> <li>Adds artifact digest as an Extended Evidence URI to the current Assurance Manifest.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Evidence-Grade Insights Human\u2013AI conclusions are promoted to signed, queryable artifacts. Full Provenance Bundle Artifacts include prompts, contexts, metrics, and outputs. Manifest Binding New evidence is discoverable via the manifest record. Auditable Lifecycle Each step leaves verifiable ledger entries."},{"location":"framework/workflows/engineer/#6-continuous-feedback-improvement","title":"6) Continuous Feedback &amp; Improvement","text":"<p>(Provide meaningful feedback for AI improvement.</p> Click to view <pre><code>sequenceDiagram\n    participant Agent as Assurance_Chat_Agent\n    participant Trust as TrustCentre\n    autonumber\n\n    %% Step 1 - Learning Feedback Loop\n    Agent-&gt;&gt;Agent: Add session context to retrieval memory\n    Agent-&gt;&gt;Agent: Store human corrections for later model reweighting\n    Agent--&gt;&gt;Agent: Future queries inherit prior insights\n\n    %% Step 2 - Periodic Verification\n    Agent-&gt;&gt;Trust: Emit insight added event\n    Trust-&gt;&gt;Trust: Reverify new artifacts\n    Trust-&gt;&gt;Trust: Reanchor digests to transparency service\n    Trust--&gt;&gt;Agent: Return updated verification record</code></pre> <p>Actors</p> <ul> <li>Assurance Chat Agent \u2013 Learns from prior interactions and corrections.  </li> <li>TrustCentre \u2013 Re-verifies new artifacts and anchors digests.  </li> </ul> <p>Actions</p> <ol> <li> <p>Learning Feedback Loop </p> <ul> <li>Adds session context to RAG; future queries inherit prior insights.  </li> <li>Human corrections are logged for re-weighting/fine-tuning.  </li> </ul> </li> <li> <p>Periodic Verification </p> <ul> <li>Ledger emits an insight-added event; TrustCentre re-verifies and re-anchors digests to Rekor.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Cumulative Intelligence Each session improves future retrieval and reasoning. Integrity Renewal New artifacts are continuously re-anchored for durability. Lower Noise Over Time Feedback reduces false positives and redundant work. Verified Learning Trail Model improvements remain auditably grounded."},{"location":"framework/workflows/engineer/#7-reporting-sharing","title":"7) Reporting &amp; Sharing","text":"<p>Generate reports and findings for the team.</p> Click to view <pre><code>sequenceDiagram\n    participant Engineer\n    participant Agent\n    participant Gate as Policy_Gate\n    participant Centre as TrustCentre\n    autonumber\n\n    %% Step 1 - Generate Analysis Summary\n    Engineer-&gt;&gt;Agent: Request summary for KMS and credential issues from past ninety days\n    Agent-&gt;&gt;Agent: Aggregate SARIF data and related findings\n    Agent-&gt;&gt;Agent: Compose risk summary and create signed markdown report with provenance\n    Agent--&gt;&gt;Engineer: Return generated report ready for review\n\n    %% Step 2 - Submit for Peer Review\n    Engineer-&gt;&gt;Gate: Attach report for validation before peer review\n    Gate-&gt;&gt;Gate: Enforce evidence schema and completeness checks\n    Gate--&gt;&gt;Engineer: Confirm report validated and accepted\n    Engineer-&gt;&gt;Centre: Make report available for supervisor or auditor verification\n    Centre--&gt;&gt;Engineer: Verification record confirmed</code></pre> <p>Actors</p> <ul> <li>Security Engineer \u2013 Requests summaries and distributes reports.  </li> <li>Assurance Chat Agent \u2013 Generates signed markdown reports and validates schema.  </li> </ul> <p>Actions</p> <ol> <li> <p>Generate Analysis Summary </p> <ul> <li>Engineer: \u201cSummarize all findings linked to KMS and credential mismanagement in the last 90 days.\u201d  </li> <li>Agent aggregates SARIF, composes risk summaries, and emits a signed Markdown report with provenance links.  </li> </ul> </li> <li> <p>Submit for Peer Review </p> <ul> <li>Attaches report to Jira/OpenProject.  </li> <li>Policy Gate enforces evidence schema and completeness before submission.  </li> <li>Supervisors/auditors can verify directly in TrustCentre.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Push-Button Reporting Curated, signed summaries with embedded evidence links. Workflow Integration Reports flow into ticketing with policy checks. Reviewer Confidence Verifiers can independently validate in TrustCentre. Consistent Narrative Reports reflect the same signed data used in analysis."},{"location":"framework/workflows/engineer/#end-state-verifiable-humanai-collaboration","title":"End-State: Verifiable Human\u2013AI Collaboration","text":"<p>At the conclusion of these workflows:</p> <ul> <li>Every question, AI response, and human action is logged in the Audit Ledger.  </li> <li>Every finding, insight, or simulated scenario is cryptographically signed and timestamped.  </li> <li>The chat transcript itself is replayable and verifiable \u2014 demonstrating explainability, traceability, and accountability.  </li> </ul> <p>Desired Outcomes</p> Outcome Description Unified, Verifiable Trail Chat, reasoning, and evidence form a single cryptographic record. Explainability by Default Reasoning traces are preserved and independently checkable. Stronger Governance Human approvals/waivers are bound to artifacts and identities. Operational Confidence Teams act on insights they can verify end-to-end."},{"location":"framework/workflows/engineer/#outcome-summary","title":"Outcome Summary","text":"Aspect Traditional Workflow Assurance Chat Workflow Data Access Manual across tools (Jira, SIEM, scanners) Unified RAG retrieval across TrustCentre + scanners Reasoning Manual correlation LLM fusion (retrievers + code + manifest) Documentation Manual report writing Auto-signed insights and ledger entries Integrity Weak (editable reports) Immutable evidence, signed, timestamped Explainability None Reasoning traces + DeepEval metrics Audit Readiness Reactive Continuous, verifiable, replayable"},{"location":"framework/workflows/engineer/#example-chat-transcript-condensed","title":"Example Chat Transcript (Condensed)","text":"<p><code>\ud83d\udc69\u200d\ud83d\udcbb Engineer: \"Show me any high EPSS vulnerabilities in the auth service since October.\"</code> <code>\ud83e\udd16 System: \"2 findings. CVE-2024-5832 (EPSS 0.93), Hardcoded JWT secret.\"</code> <code>\ud83d\udc69\u200d\ud83d\udcbb Engineer: \"Simulate attack chain combining those two.\"</code> <code>\ud83e\udd16 System: \"Critical chain detected: Token forgery possible. CVSSv3=9.1. Evidence: ledger:evt-524. Mitigation: Rotate secret, enforce KMS policy SEC-08.\"</code> <code>\ud83d\udc69\u200d\ud83d\udcbb Engineer: \"Record as insight and sign.\"</code> <code>\ud83e\udd16 System: \"Insight signed. Artifact: oci://trustcentre/org/secinsight@sha256:ae9f\u2026 anchored to Rekor log 9821.\"</code> </p>"},{"location":"framework/workflows/system/","title":"Core Processes","text":""},{"location":"framework/workflows/system/#1-assurance-manifest-defintion","title":"1) Assurance Manifest Defintion","text":"<p>Declaring what trusted looks like</p> Click to view <pre><code>sequenceDiagram\n    participant Customer\n    participant Vendor\n    participant TrustCentre\n    autonumber\n\n    Customer-&gt;&gt;Vendor: Initiate assurance discussion\n    Vendor--&gt;&gt;Customer: Propose applicable frameworks\n    Customer-&gt;&gt;Vendor: Confirm scope (ISO27001, SOC2, NIST, SLSA, AI Assurance)\n    Vendor-&gt;&gt;Vendor: Incorporate threat-model findings\n\n    Customer-&gt;&gt;Vendor: Co-author Assurance Manifest\n    Vendor--&gt;&gt;Customer: Draft for review\n    Customer-&gt;&gt;TrustCentre: Submit baseline manifest for registration\n    TrustCentre--&gt;&gt;Customer: Acknowledge and timestamp\n    TrustCentre--&gt;&gt;Vendor: Confirm manifest visibility/version\n    Vendor--&gt;&gt;Customer: Apply updates and finalize\n    Customer-&gt;&gt;TrustCentre: Publish Manifest v1.0\n    TrustCentre--&gt;&gt;Customer: Immutable record created\n    TrustCentre--&gt;&gt;Vendor: Manifest available to pipeline</code></pre> <p>Actors</p> <ul> <li>Customer / Procurer \u2013 requires proof the system meets security, privacy, and AI assurance requirements.  </li> <li>Vendor / Provider \u2013 owns the system under test and evidence generation.</li> </ul> <p>Actions</p> <ol> <li> <p>Joint Framework Alignment</p> <ul> <li>Customer and Vendor agree on which frameworks apply: e.g., ISO 27001, SOC 2, NIST 800-53, SLSA, AI-Assurance (bias / privacy / drift).  </li> <li>Each requirement maps to measurable controls and test criteria (e.g., \u201cno critical CVEs,\u201d \u201cmodel fairness threshold &gt; 0.9\u201d).  </li> <li>Threat-modelling findings could be incorporated.</li> </ul> </li> <li> <p>Author Assurance Manifest</p> <ul> <li>Both parties collaboratively define an Assurance Manifest (language e.g. YAML / JSON / Markdown / CUE TBD).  </li> <li>Manifest lists:  <ul> <li>required proofs (security, integrity, privacy, AI behavior)  </li> <li>scan schedule (e.g., nightly, release-gated)  </li> <li>success / failure thresholds  </li> <li>responsible parties and evidence sinks.</li> </ul> </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Mutual Assurance Understanding Customer and Vendor share a unified interpretation of what \u201cassured\u201d means for this system \u2014 including scope, frameworks, and testing expectations. Framework-to-Control Mapping Each selected framework requirement (e.g., ISO 27001 A.12.6.1 or NIST 800-53 RA-5) is mapped to measurable, testable controls within the system. Defined Success Criteria Quantitative pass/fail thresholds are explicitly defined \u2014 e.g., \u201cno critical CVEs,\u201d \u201cmodel fairness &gt; 0.9,\u201d or \u201czero privacy violations.\u201d Threat Model Integration Threat-modelling findings are aligned with assurance tests so high-risk attack paths are continuously covered by scanning or attestations. Signed Assurance Manifest A machine-readable, digitally signed manifest defines what will be tested, how often, by which tools, and where evidence will be stored. Immutable Provenance Record An in-toto attestation records the manifest\u2019s signature, timestamp, and authorship for auditability inside the TrustCentre. Role Accountability Assignment Both parties have clear ownership of assurance activities such as scanning, sign-off, and evidence review. Trust Baseline Established The measurable baseline for ongoing automated assurance is now defined \u2014 future scans and attestations will compare against this state."},{"location":"framework/workflows/system/#2-scheduled-assurance-execution","title":"2) Scheduled Assurance Execution","text":"<p>Running an assurance check</p> Click to view <pre><code>sequenceDiagram\n    participant ORCH as Pipeline_Orchestrator\n    participant SUT as Systems_Under_Test\n    participant OCI as TrustCentre_OCI\n    participant RAG as AI_Retrievers\n    autonumber\n\n    %% Manifest Retrieval\n    ORCH-&gt;&gt;OCI: Pull latest Assurance Manifest\n    OCI--&gt;&gt;ORCH: Manifest + signature + timestamp\n    ORCH-&gt;&gt;ORCH: Verify signature and timestamp\n    Note right of ORCH: Manifest verified\n\n    %% Scanning Phase\n    ORCH-&gt;&gt;SUT: Run scanners (OpenGrep, Trivy, Presidio, Checkov, SCA)\n    SUT--&gt;&gt;ORCH: JSON, SARIF, logs\n    ORCH-&gt;&gt;SUT: Run AI probes (drift, bias, prompt-safety)\n    SUT--&gt;&gt;ORCH: Probe results\n    ORCH-&gt;&gt;ORCH: Hash outputs + record versions\n\n    %% Raw Ingestion into RAG Memory\n    ORCH-&gt;&gt;RAG: Index code corpus + scan outputs\n    RAG--&gt;&gt;ORCH: Ingest complete\n\n    %% Evidence (optional)\n    ORCH-&gt;&gt;OCI: Push artifacts + metadata (immutable)</code></pre> <p>Actors</p> <ul> <li>Pipeline Orchestrator \u2013 Executes scheduled workflows using systems such as GitHub Actions, Dagger, or Tekton.  </li> <li>Systems Under Test \u2013 Code repositories, applications, and services being continuously validated.  </li> </ul> <p>Actions</p> <ol> <li> <p>Manifest Retrieval </p> <ul> <li>On the defined cadence, the orchestrator pulls the latest Assurance Manifest from the TrustCentre\u2019s OCI.  </li> <li>Orchestrator verifies digital signature and timestamp before execution.  </li> </ul> </li> <li> <p>Scanning Phase </p> <ul> <li>Executes declared tools:  <ul> <li>e.g., OpenGrep, Trivy, Presidio, Checkov, or SCA for code, IaC, and privacy scanning.  </li> <li>e.g., Custom AI assurance probes for drift, bias, and prompt safety validation.  </li> </ul> </li> <li>Collects raw outputs (JSON, SARIF, logs) and hashes them for provenance integrity.  </li> </ul> </li> <li> <p>Raw Ingestion into RAG Memory </p> <ul> <li>Both the raw code corpus and raw scan results are indexed into the AI Reasoning Rail\u2019s retrievers for semantic enrichment and historical traceability.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Automated Cadence Enforcement Assurance tests execute on a defined schedule or event trigger, ensuring continuous visibility without manual intervention. Verified Manifest Integrity Each run confirms the authenticity and version of the Assurance Manifest before initiating tests. Multi-Domain Scanning Coverage Security, privacy, and AI behavior scans run in a single orchestrated flow with unified evidence capture. Provenance Preservation Every scan result is hashed, timestamped, and linked to its manifest and tool version for auditability. RAG Memory Integration Raw results are ingested into the AI Reasoning Rail\u2019s retrievers to enable semantic recall, enrichment, and longitudinal assurance analysis. Continuous Assurance Loop Establishes a foundation for autonomous, trust-based validation that feeds future assurance reports and reasoning cycles."},{"location":"framework/workflows/system/#3-normalization-contextualization","title":"3) Normalization &amp; Contextualization","text":"<p>Make the data more useful</p> Click to view <pre><code>sequenceDiagram\n    participant NORM as Normalization_Component\n    participant AI as AI_Retrievers_Fusion_Engine\n    autonumber\n\n    %% Format Normalization\n    NORM-&gt;&gt;NORM: Convert raw scanner outputs to SARIF v2.1.0\n    NORM-&gt;&gt;NORM: Extract rule ID, severity, file path, line range, message\n    Note right of NORM: Creates consistent schema for cross-tool comparability\n\n    %% Fingerprinting &amp; Deduplication\n    NORM-&gt;&gt;NORM: Compute stable hashes per finding (rule ID + line context)\n    NORM-&gt;&gt;NORM: Deduplicate across scanners and prior runs\n    Note right of NORM: Ensures stable tracking of recurring issues\n\n    %% Severity Mapping\n    NORM-&gt;&gt;NORM: Map tool-specific severities to unified scale (Critical\u2192High\u2192Medium\u2192Low)\n    Note right of NORM: Standardized severity aids downstream analysis\n\n    %% Contextual Augmentation\n    NORM-&gt;&gt;AI: Send normalized and deduped findings\n    AI-&gt;&gt;AI: Retrieve related code snippets, commit messages, manifest clauses\n    AI-&gt;&gt;AI: Perform embedding search and semantic grouping\n    AI--&gt;&gt;NORM: Return enriched, context-aware findings</code></pre> <p>Actors</p> <ul> <li>Normalization Component \u2013 Standardizes raw outputs into a consistent schema for cross-tool comparability.  </li> <li>AI Retrievers / Fusion Engine \u2013 Enrich findings with contextual and semantic metadata to improve downstream analysis.  </li> </ul> <p>Actions</p> <ol> <li> <p>Format Normalization </p> <ul> <li>Converts scanner output into standard SARIF v2.1.0 schema.  </li> <li>Extracts common fields: rule ID, severity, file path, line range, and message.  </li> </ul> </li> <li> <p>Fingerprinting &amp; Deduplication </p> <ul> <li>Computes stable hashes per finding (rule ID + line context).  </li> <li>Deduplicates across scanners and previous runs using hash comparison to ensure stable tracking.  </li> </ul> </li> <li> <p>Severity Mapping </p> <ul> <li>Normalizes all tool-specific severities to a unified scale (e.g., Critical \u2192 High \u2192 Medium \u2192 Low).  </li> </ul> </li> <li> <p>Contextual Augmentation </p> <ul> <li>AI Retrievers pull nearby source code snippets, commit messages, and manifest clauses related to each finding.  </li> <li>Embedding search enables semantic grouping of similar issues for cross-scan reasoning.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Consistent Data Structure All scanner outputs are normalized to the SARIF standard, ensuring compatibility across tools and systems. Duplicate-Free Findings Fingerprinting guarantees stable identifiers for findings, eliminating redundancy across scans and runs. Unified Severity Model Findings from different scanners are mapped to a single, normalized severity scale for accurate prioritization. Contextually Enriched Evidence Each finding is paired with relevant source code, commit context, and assurance manifest references. Semantic Grouping Related issues are clustered through embedding similarity, improving reasoning and triage efficiency. TrustCentre-Ready Data Clean, deduplicated, and semantically enriched records are prepared for storage, visualization, and policy evaluation in the TrustCentre."},{"location":"framework/workflows/system/#4-enrichment-threat-assurance-policy","title":"4) Enrichment (Threat, Assurance &amp; Policy)","text":"<p>Enrich the data to make it more meaningful</p> Click to view <pre><code>sequenceDiagram\n    participant ENR as Enrichment_Service\n    participant AI as AI_Fusion_Logic_LLM_Chain\n    autonumber\n\n    %% Threat Enrichment\n    ENR-&gt;&gt;ENR: Lookup CVSS, CWE, CPE, EPSS, CISA KEV, patch data\n    ENR-&gt;&gt;AI: Provide enriched findings\n    AI-&gt;&gt;AI: Re-rank findings by context and exploitability\n    Note right of AI: Context-aware prioritization based on enrichment metadata\n\n    %% AI Contextual Reasoning\n    AI-&gt;&gt;AI: Analyze findings vs Assurance Manifest goals\n    AI-&gt;&gt;AI: Generate human-readable summaries + remediation guidance\n    Note right of AI: Aligns results with assurance and mitigation objectives\n\n    %% AI Safety &amp; Schema Gate\n    AI-&gt;&gt;AI: Validate outputs against expected JSON schema\n    AI-&gt;&gt;AI: Run DeepEval / Guardrails for faithfulness + consistency checks\n    Note right of AI: Ensures outputs are trustworthy and structured\n\n    %% Policy Decision Preparation\n    AI-&gt;&gt;ENR: Return policy-ready findings\n    ENR-&gt;&gt;ENR: Tag each finding with pass / fail / waiver\n    ENR-&gt;&gt;ENR: Format data for downstream Policy Gate</code></pre> <p>Actors</p> <ul> <li>Enrichment Service \u2013 Performs correlation, lookup, and contextual threat analysis.  </li> <li>AI Fusion Logic / LLM Chain \u2013 Conducts reasoning, summarization, and policy preparation.  </li> </ul> <p>Actions</p> <ol> <li> <p>Threat Enrichment </p> <ul> <li>Looks up CVSS, CWE, CPE, EPSS, CISA KEV, and patch availability.  </li> <li>The AI Fusion Engine re-ranks findings by context and exploitability.  </li> </ul> </li> <li> <p>AI Contextual Reasoning </p> <ul> <li>The LLM Chain analyzes findings against Assurance Manifest goals.  </li> <li>Generates human-readable summaries and recommended remediation actions.  </li> </ul> </li> <li> <p>AI Safety &amp; Schema Gate </p> <ul> <li>Structured outputs are validated against expected JSON schemas.  </li> <li>Tools such as DeepEval or Guardrails run faithfulness and consistency checks.  </li> </ul> </li> <li> <p>Policy Decision Preparation </p> <ul> <li>Each finding is tagged with a preliminary policy outcome: <code>pass | fail | waiver</code>.  </li> <li>Data is formatted for downstream Policy Gate evaluation.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Threat Intelligence Integration Findings are enriched with real-world exploit data and threat context (CVSS, EPSS, KEV). Context-Aware Reasoning AI Fusion aligns findings with Assurance Manifest objectives to generate meaningful insights. Validated AI Outputs Schema and consistency checks ensure reasoning results are structurally correct and faithful. Policy-Ready Data Findings are pre-labeled for automated evaluation, reducing human review load. Enhanced Prioritization Issues are ranked by exploitability and assurance relevance, improving focus and response time. Assurance-Linked Context Each enriched record maintains its provenance and linkage to manifest controls."},{"location":"framework/workflows/system/#5-policy-gate-human-in-the-loop","title":"5) Policy Gate &amp; Human-in-the-Loop","text":"<p>Double check that the outputs are legitimate</p> Click to view <pre><code>sequenceDiagram\n    participant PolicyEngine\n    participant HumanReviewers\n    participant AuditLedger\n    autonumber\n\n    PolicyEngine-&gt;&gt;PolicyEngine: Evaluate findings vs Manifest criteria\n    PolicyEngine-&gt;&gt;PolicyEngine: Rule: No Critical CVEs = Fail\n    PolicyEngine-&gt;&gt;PolicyEngine: Rule: Bias under threshold = Pass\n\n    PolicyEngine-&gt;&gt;HumanReviewers: Route low-confidence findings (confidence under 85 percent)\n    HumanReviewers-&gt;&gt;HumanReviewers: Review, waive, approve, or reject\n    HumanReviewers--&gt;&gt;PolicyEngine: Return decision and rationale\n\n    PolicyEngine-&gt;&gt;AuditLedger: Log automated results\n    HumanReviewers-&gt;&gt;AuditLedger: Log manual results (signatures, timestamps)\n    AuditLedger--&gt;&gt;PolicyEngine: Return policy hash and audit reference</code></pre> <p>Actors</p> <ul> <li>Policy Engine (CUE / OPA) \u2013 Applies machine-enforceable logic to evaluate compliance.  </li> <li>Human Reviewers / Approvers \u2013 Provide oversight for exceptions, uncertainty, and critical waivers.  </li> </ul> <p>Actions</p> <ol> <li> <p>Automated Policy Evaluation </p> <ul> <li>Policy-as-code logic compares each finding to Manifest criteria.  </li> <li>Examples: \u201cNo Critical CVEs \u2192 Fail,\u201d \u201cAll AI bias tests &lt; 0.05 \u2192 Pass.\u201d  </li> </ul> </li> <li> <p>Human Review Trigger </p> <ul> <li>If AI or policy confidence &lt; threshold (e.g., 0.85), issue is routed to the Human-in-the-Loop Panel.  </li> <li>Reviewers can waive, approve, or reject findings with justification.  </li> </ul> </li> <li> <p>Audit Recording </p> <ul> <li>Every decision (automated or manual) is logged to the Audit Ledger with signatures, timestamps, and policy hashes.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Automated Policy Enforcement Objective criteria are applied at scale with transparent, machine-readable logic. Human Oversight for Edge Cases Human reviewers handle low-confidence or exception scenarios for accountability. Immutable Audit Trail All actions are recorded with cryptographic evidence and versioned policy states. Waiver Traceability Every manual exception is logged and linked to an auditable approval record. Balanced Governance Automation accelerates compliance while preserving human judgment where needed. Feedback Loop to AI Models Human decisions are re-ingested into the AI Reasoning Rail for model improvement."},{"location":"framework/workflows/system/#6-evidence-finalization-signing","title":"6) Evidence Finalization &amp; Signing","text":"<p>Sign and attest the findings</p> Click to view <pre><code>sequenceDiagram\n    participant GATE as Policy_Gate_Sign_Verify_Service\n    participant TSA as Time_Stamp_Authority\n    participant LED as Audit_Ledger\n    participant CUST as Customer\n    autonumber\n\n    %% Report Assembly\n    GATE-&gt;&gt;GATE: Aggregate SARIF, AI summaries, policy verdicts, approvals\n    GATE-&gt;&gt;GATE: Build Final Assurance Report\n    Note right of GATE: Unified evidence package for signing\n\n    %% Evidence Signing &amp; Publication\n    GATE-&gt;&gt;GATE: Sign report with TrustCentre-managed keys\n    GATE-&gt;&gt;TSA: Request timestamp proof\n    TSA--&gt;&gt;GATE: Return trusted timestamp\n    GATE-&gt;&gt;LED: Record artifact digest, signer, timestamp, metadata\n    GATE-&gt;&gt;GATE: Publish signed report to WORM OCI (Write Once Read Many)\n    Note right of GATE: Rekor transparency log entry created\n\n    %% Feedback to Customer\n    GATE--&gt;&gt;CUST: Provide URI to signed artifact\n    CUST-&gt;&gt;CUST: Verify signature via Sigstore/Rekor CLI\n    Note right of CUST: Independent verification ensures trust and transparency</code></pre> <p>Actors</p> <ul> <li>Policy Gate / TrustCentre Sign-Verify Service \u2013 Aggregates assurance artifacts and performs digital signing.  </li> </ul> <p>Actions</p> <ol> <li> <p>Report Assembly </p> <ul> <li>Combines all results (SARIF, AI recommendations, policy verdicts, approvals) into a Final Assurance Report.  </li> </ul> </li> <li> <p>Evidence Signing &amp; Publication </p> <ul> <li>The report is digitally signed using TrustCentre-managed keys.  </li> <li>Published to the WORM OCI (Write Once Read Many).  </li> <li>Logged to Rekor and timestamped by a Time Stamping Authority (TSA).  </li> <li>The Audit Ledger records artifact digest, signer, and result metadata.  </li> </ul> </li> <li> <p>Feedback to Customer </p> <ul> <li>Customer receives a URI to the signed artifact.  </li> <li>Verification can be performed via Sigstore / Rekor CLI, independently of the vendor\u2019s pipeline.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Comprehensive Assurance Report A complete record of tests, findings, and approvals is compiled into a single signed artifact. Cryptographically Signed Evidence Digital signatures ensure authenticity, integrity, and non-repudiation of assurance results. Tamper-Evident Publication Reports are stored immutably in a WORM registry with transparency logs. Independent Verification Customers can verify signatures and timestamps without relying on vendor systems. Traceable Provenance Chain Every artifact links back to its manifest, scanner, policy, and signer identity. Immutable Assurance Ledger A permanent, auditable record of the entire assurance lifecycle is maintained."},{"location":"framework/workflows/system/#7-metrics-visualization-continuous-learning","title":"7) Metrics, Visualization &amp; Continuous Learning","text":"<p>Interact and learn from the outcomes</p> Click to view <pre><code>sequenceDiagram\n    participant MET as Metrics_Service\n    participant DASH as Dashboard\n    participant AI as AI_Analyst_Module\n    participant LED as Audit_Ledger\n    autonumber\n\n    %% Data Aggregation\n    MET-&gt;&gt;MET: Ingest ledger and report data\n    MET-&gt;&gt;MET: Transform and store in metrics warehouse (Prometheus / Grafana / BigQuery)\n    Note right of MET: Aggregates assurance artifacts for analysis\n\n    %% Visualization\n    MET-&gt;&gt;DASH: Provide compliance, trend, and accuracy datasets\n    DASH-&gt;&gt;DASH: Render compliance status, MTTA, assurance trends\n    Note right of DASH: Visualizes KPIs and historical assurance metrics\n\n    %% RAG Memory Refinement\n    MET-&gt;&gt;AI: Send historical findings and outcomes\n    AI-&gt;&gt;AI: Analyze false positives, waived findings, drift patterns\n    AI-&gt;&gt;AI: Update retriever index and fusion weights\n    Note right of AI: Improves future assessments via continuous learning\n\n    %% Trust Re-Anchoring\n    MET-&gt;&gt;LED: Re-sign and re-anchor ledger roots\n    LED--&gt;&gt;MET: Confirm Rekor / blockchain timestamp\n    Note right of LED: Ensures long-term verifiable continuity of trust</code></pre> <p>Actors</p> <ul> <li>Metrics Service \u2013 Aggregates and transforms assurance data for analysis.  </li> <li>Dashboard \u2013 Visualizes compliance and performance metrics.  </li> <li>AI Analyst Module \u2013 Continuously refines models and retrievers based on historical outcomes.  </li> </ul> <p>Actions</p> <ol> <li> <p>Data Aggregation </p> <ul> <li>Ingests ledger and report data into a metrics warehouse (e.g., Prometheus, Grafana, or BigQuery).  </li> </ul> </li> <li> <p>Visualization </p> <ul> <li>Displays compliance status, assurance trends, mean-time-to-assure (MTTA), and AI accuracy over time.  </li> </ul> </li> <li> <p>RAG Memory Refinement </p> <ul> <li>AI system learns from historical patterns (e.g., false positives, waived findings).  </li> <li>Updates retriever index and fusion weights to improve future assessments.  </li> </ul> </li> <li> <p>Trust Re-Anchoring </p> <ul> <li>Periodically re-signs and re-anchors ledger roots to transparency services (e.g., Rekor, blockchain).  </li> <li>Ensures long-term non-repudiation and verifiable continuity of trust.  </li> </ul> </li> </ol> <p>Desired Outcomes</p> Outcome Description Operational Insight Dashboards provide visibility into assurance posture, trends, and performance indicators. Continuous Model Improvement AI systems adapt based on historical data to enhance reasoning accuracy. Reduced False Positives Feedback loops filter noise and improve signal quality in findings. Transparency Anchoring Ledger re-signing maintains long-term verifiability across audit periods. Actionable Metrics Quantitative metrics enable teams to prioritize improvements and track MTTA / assurance SLAs. Adaptive Assurance System The entire pipeline evolves toward higher trust and efficiency through data-driven learning."},{"location":"framework/workflows/system/#end-state-verifiable-trust-loop","title":"End-State: Verifiable Trust Loop","text":"<p>Every artifact\u2014manifest, scan result, AI analysis, and final report\u2014is:</p> <ul> <li>Signed by verified identities,  </li> <li>Timestamped and immutable,  </li> <li>Traceable through the Audit Ledger and Rekor,  </li> <li>Linked to the original Assurance Manifest defining the expected controls.  </li> </ul> <p>Desired Outcomes</p> Outcome Description End-to-End Verifiability Each assurance artifact is cryptographically linked, signed, and auditable. Customer Assurance Confidence Customers can independently verify that agreed-upon assurance criteria were met on a given date. Vendor Proof of Diligence Vendors demonstrate that every control was tested and logged in a tamper-evident system. Mutual Trust Framework Both parties share a provable assurance baseline governed by transparent evidence. Immutable Trust Ledger The system provides a continuous, cryptographic chain of custody for all assurance activities. Assured System Integrity Completes the feedback loop between evidence, policy, and verification \u2014 forming a persistent trust ecosystem."},{"location":"getting%20started/","title":"Pre-Alpha Notice","text":"<p>Certus TAP is currently in a pre-alpha phase of development. At this stage, the framework is under active design and experimentation, but installation or deployment guidance is not yet available.</p> <p>This page currently serves as a placeholder until formal documentation and setup instructions are released. As the project evolves, we\u2019ll update this page with new details, examples, and release notes.</p> <p>Stay tuned for updates as Certus TAP PoC progresses toward its first public release. In the meantime . . .</p> <p> Review the framework - If you want to broaden your understanding of Certus Tap and the design decisions taken by this community, then this is a great place to start. Take a look on the framework section for more information about what we plan to do!</p> <p> Join the community - Prefer to engage and explore CertusTAP with others?  Then join in!  Everything is public and open to friendly debate.  Take a look on the community section for more information about how you can get engaged with this initiative.</p>"},{"location":"getting%20started/license/","title":"License","text":"<p>MIT License</p> <p>Copyright \u00a9 2025 Martin Harrod</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"getting%20started/poc/","title":"Proof of Concept","text":"<p>Although the focus of this project is on building a framework and ontological foundation, it is still important to have a prescriptive Proof of Concept (PoC) to keep us centered in reality.   This PoC demonstrates how the framework can operate end-to-end using real open-source components. It serves as both an example implementation and a validation environment for the trust and assurance lifecycle.</p> <p>Below is the stack we will use. It is not the only way, but a reference design that others can build upon, extend, or replace with their preferred technologies. Admittedly, this PoC is necessarily complex and our future goal would be to build a much simpler system that anyone could deploy and use.</p> <p> We strongly recommend that you review the entire framework before delving deep into the PoC!</p> Click to view Architecture <p></p>"},{"location":"getting%20started/poc/#reference-implementation-overview","title":"Reference Implementation Overview","text":""},{"location":"getting%20started/poc/#infrastructure-and-development-stack","title":"Infrastructure and Development Stack","text":"Category Tooling / Technology Purpose Language Runtime Python 3.12 Core runtime for assurance services, pipelines, and agents. Application Framework FastAPI Lightweight async framework for APIs and service orchestration. Dependency Management Poetry Manages Python dependencies and virtual environments. Containerization Docker / Podman / Colima (macOS) Builds isolated, reproducible dev and runtime environments. Container Runtime containerd / CRI-O Executes containers within Tekton / Kubernetes nodes. Orchestration Kubernetes / Kind (local) Manages workloads and simulates production assurance clusters locally. Workflow Execution Tekton Pipelines Executes multi-stage CI/CD and assurance workflows in-cluster. Image Builders (in-cluster) Kaniko / Buildpacks / Buildah Builds container images in Tekton without requiring Docker daemons. Local Development Dev Containers / VS Code Provides reproducible, containerized developer environments. GPU Cloud / Hybrid Compute Runpod On-demand GPU instances for large-model inference, fine-tuning, or evaluation tasks. Registry &amp; Artifacts Harbor (OCI, WORM mode) Stores signed, immutable assurance artifacts and container images. Networking / Ingress Traefik Routes and secures ingress traffic for PoC services. Secrets &amp; Identity Vault / OIDC / Sigstore keyless Manages credentials, identity tokens, and signing keys for assurance trust. Observability Prometheus + Grafana Monitors assurance metrics, pipeline health, and runtime performance. Logging &amp; Tracing Loki + OpenTelemetry Collects logs and traces across distributed assurance components. Storage MinIO / LocalStack S3 Provides cloud-style object storage for assurance data, evidence, and logs. CI/CD Integration GitHub Actions / GitLab CI/CD Triggers Tekton pipelines on commits or policy updates. Supply-Chain Attestation Tekton Chains + Cosign Signs and verifies provenance for builds and assurance artifacts."},{"location":"getting%20started/poc/#ai-technology-stack","title":"AI Technology Stack","text":"Layer Implementation Purpose Model Runtime (Local) Ollama (Llama 3.1 8B / Qwen 2.5 7B) Local inference for reasoning and assurance generation loops. Model Runtime (Cloud / Hybrid) Runpod Inference Pods Offloads heavy models (e.g., Mixtral 8\u00d77B, Llama 70B) for parallel or long-context evaluation. RAG / Orchestration Haystack 2 Pipelines Retrieval \u2192 Generation \u2192 Post-Processing workflows. Embeddings Sentence-Transformers Dense retrieval, reranking, and semantic similarity. Data Privacy Presidio PII redaction and masking within AI data flows. Config &amp; Schema Pydantic / JSON Schema Typed I/O contracts and config validation. Storage / Artifacts Local FS / S3 (LocalStack) Persists corpora, indexes, and model run artifacts."},{"location":"getting%20started/poc/#trust-centre-technology-stack","title":"Trust Centre Technology Stack","text":"Function / Layer Implementation Purpose Trust Primitives Sigstore (Cosign, Rekor), RFC 3161 Signing, timestamping, transparency-log provenance. Policy Engine Open Policy Agent (OPA) / CUE Policy-as-code evaluation and decisions. Identity &amp; Key Mgmt OIDC, GPG, keyless Sigstore AuthN/Z and non-repudiation for actors and artifacts. Evidence Registry Harbor (OCI, WORM) Immutable storage of signed assurance artifacts and logs. (Optional) Orchestration Tekton (primary), Dagger (local prototyping optional) Pipeline execution; Dagger optional if you still want local proto flows."},{"location":"getting%20started/poc/#core-assurance-operations","title":"Core Assurance Operations","text":"Function / Layer Implementation Purpose Security Scanning Trivy, Semgrep, Syft/Grype, OpenGrep, Gitleaks Detect vulnerabilities, misconfigurations, secrets, and SBOM drift. AI Assurance (Behavior &amp; XAI) Haystack + Presidio + Ollama + DeepEval + LIME/SHAP/Captum Evaluate behavior, bias, safety drift; explain model reasoning. Traditional Software Testing pytest, k6, Playwright, Postman Functional, performance, and integration testing. Normalization Layer Custom normalizer + JSON Schema + Pandera Unify heterogeneous outputs into a common schema. Fusion Logic Engine Python/Haystack + CUE/OPA rules Correlate, enrich, and fuse findings across domains. Policy-as-Code / Gating CUE + OPA Enforce structured assurance logic; compute pass/fail outcomes. Schema &amp; Safety Engine Pydantic + JSON Schema Validate outputs against format and safety constraints. Human-in-the-Loop OpenProject + JSON waivers Traceable manual overrides and waiver governance. Metrics &amp; Visualization Prometheus + Grafana Monitor KPIs, pipeline health, reasoning metrics. Audit &amp; Evidence Ledger Rekor + Evidence URIs Immutable provenance and end-to-end traceability."},{"location":"getting%20started/poc/#ai-assurance-tooling-validation-explainability","title":"AI Assurance Tooling (Validation &amp; Explainability)","text":"Category Tooling Purpose Behavioral Metrics DeepEval Correctness/faithfulness/safety metrics. Privacy &amp; Safety Presidio (assurance mode) Detect PII leakage and policy violations. Explainability LIME / SHAP / Captum Local/global interpretability of outputs. Schema Validation Pydantic / JSON Schema Enforce structured, predictable outputs. Policy &amp; Governance CUE / OPA Pass/fail criteria across checks. Evidence &amp; Provenance Cosign / Rekor Sign and log assurance reports and SBOMs. Publication Harbor (OCI, WORM) Immutable artifact storage for audits. Observability Prometheus + Grafana Drift and KPI dashboards."},{"location":"getting%20started/poc/#flow-summary","title":"Flow Summary","text":"<ol> <li>Run the Stack \u2014 The AI pipeline (Haystack + Ollama + Presidio) generates outputs and reasoning traces.  </li> <li>Assure Outputs \u2014 DeepEval, LIME/SHAP/Captum, and schema checks validate safety, fairness, and structure.  </li> <li>Policy Gate \u2014 CUE/OPA enforces trust and compliance rules; human overrides create signed waivers.  </li> <li>Sign &amp; Publish \u2014 Assurance artifacts are cryptographically signed and stored immutably in Harbor.  </li> <li>Monitor &amp; Iterate \u2014 Grafana visualizes model performance, drift, and safety compliance trends.</li> </ol>"},{"location":"getting%20started/roadmap/","title":"Roadmap","text":"<p>This roadmap outlines the evolution of the Certus TAP PoC from foundational R&amp;D to a fully autonomous, trust-centric ecosystem. Each phase strengthens the integration of AI reasoning, immutable evidence, and human oversight.  We are aiming to ensure that assurance processes remain transparent, verifiable, and explainable. </p> <p>By progressing through a structured Crawl \u2192 Walk \u2192 Run \u2192 Fly approach, we hope to transform early experimental prototypes into production-grade, federated systems capable of sustaining continuous cross-organizational trust validation.</p> <p>Here is a summary of each phase:</p> Crawl \u2014 Exploration &amp; Foundational R&amp;D Category Focus Outcomes Core Platform Establish reproducible local development using Python, Poetry, and Docker. Setup LocalStack(s3) + Harbor registries. Define assurance manifest schemas. Foundational CLI scripts, developer reproducibility, and schema prototypes. Orchestration Pipeline Prototype Tekton-based workflows for signed evidence capture. Integrate initial scanner outputs (OpenGrep, Trivy, Presidio). First end-to-end PoC for evidence registration and signature verification. AI Reasoning Rail Minimal; exploratory use of Haystack + LLM for privacy text analysis and metadata tagging. Early experiments in reasoning trace capture for explainability. Trust Centre Introduce Sigstore, RFC 3161 timestamp proofs, and Rekor transparency log. Immutable provenance for early evidence artifacts. Other Documentation and design decision logs; initial architecture diagrams. Shared R&amp;D record for structured next-phase development. Walk \u2014 Structured Development &amp; CLI-Driven Workflows Category Focus Outcomes Core Platform Harden development stack (FastAPI services, Tekton deployment templates, VS Code devcontainers). Reproducible local/test environments and schema validation via CI. Orchestration Pipeline Implement Tekton pipelines with Cosign signing, RFC 3161 timestamps, and consistent artifact schemas (SARIF/JSON). Reliable CLI tools and containerized pipeline execution. AI Reasoning Rail Integrate reasoning outputs into normalization pipeline; start tracking explainability metrics via DeepEval. Structured reasoning traces linked to artifacts. Trust Centre Deploy Harbor WORM registry and enforce signature verification on upload. Authenticated, timestamped artifacts with provenance. Other Early dashboard for evidence status; internal SME alpha feedback loops. Alpha validation of usability and reproducibility. Run \u2014 Defined Scope &amp; Production-Ready Capabilities Category Focus Outcomes Core Platform Harden container images, policies, and security posture; integrate observability (Prometheus/Grafana). Stable, secure deployment baseline for SMEs and auditors. Orchestration Pipeline Expand Tekton pipelines for full assurance loops: scanning \u2192 normalization \u2192 enrichment \u2192 gating \u2192 signing. End-to-end traceability across all pipeline steps. AI Reasoning Rail Operate reasoning components continuously: contextual analysis, bias/fairness checks, narrative generation. Explainable reasoning reports embedded in assurance outputs. Trust Centre Enable governance enforcement (signature chains, audit logs, waivers). Integrate Rekor + Cosign verification APIs. Production-grade evidence integrity verification and audit readiness. Other Dashboards visualizing compliance, drift, and reasoning quality. Live reporting and trace validation for auditors and SMEs. Fly \u2014 Autonomous, Trust-Centric Ecosystem Category Focus Outcomes Core Platform Deliver cloud-depoyable architecture and optimize performance for production use. Scalable, resilient \u201cAssurance as a Service\u201d platform. Orchestration Pipeline Introduce self-healing pipelines with AI-driven scheduling and dynamic resource allocation. Autonomous orchestration with adaptive policy control. AI Reasoning Rail Continuous, autonomous AI reasoning with human oversight; AI validation of reasoning reliability and bias drift. Trustworthy, co-signed AI reasoning evidence with transparency dashboards. Trust Centre Federated attestation exchange, cross-org signing, and provenance APIs. Global trust fabric with verifiable, replayable attestations. Other Unified UI for policy authors, transparency reports, and governance analytics. Human\u2013AI collaboration with complete evidence traceability."},{"location":"getting%20started/roadmap/#crawl-to-walk-next-6-months","title":"Crawl-to-Walk (next 6-months)","text":"<p>The project is currently in Crawl and moving towards Walk, we are focusing on:</p> <ul> <li>Open-ended R&amp;D and architectural experimentation  </li> <li>Iterative prototyping with reproducibility and immutability foundations  </li> <li>Designing schemas, manifests, and reasoning validation frameworks  </li> <li>Preparing the transition to Walk with CLI and CI/CD integration groundwork</li> </ul>"},{"location":"getting%20started/roadmap/#a-foundation-evidence-layer","title":"\ud83d\udd35  A \u2014 Foundation &amp; Evidence Layer","text":"<p> Goal: Establish reproducible environments, baseline security hygiene, and immutable storage foundations.</p> Category Focus / Deliverables Success Criteria Core Platform Local reproducible setup with Python + Poetry; LocalStack + Harbor registries; baseline Tekton pipelines. All developers can spin up identical local environments via devcontainer or Makefile. Orchestration Pipeline Simple Dagger \u2192 Tekton prototype for signed artifact flow; reproducible build/test stages. Tekton pipeline runs end-to-end locally, generating signed artifacts. AI Reasoning Rail None initially \u2014 focus on reproducibility for future reasoning traceability. Reasoning interface stubbed and schema placeholder defined. Trust Centre Introduce Cosign signing, RFC 3161 timestamps, Rekor integration for immutable attestations. Cosign + Rekor verification successful on all sample evidence. Other Architecture documentation and assurance manifest schema version-controlled. Schema and CLI prototype merged and reviewed in repo."},{"location":"getting%20started/roadmap/#b-normalization-schema-standardization","title":"\ud83d\udfe1 B \u2014 Normalization &amp; Schema Standardization","text":"<p> Goal: Build the unified schema for assurance data across scanners, enrichers, and policy gates.</p> Category Focus / Deliverables Success Criteria Core Platform Schema registry for scanner outputs and evidence formats. Schema registry accessible and versioned in repository. Orchestration Pipeline Normalization engine emitting SARIF + JSON with fingerprinting and severity mapping. All scanners emit normalized SARIF or JSON with valid fingerprints. AI Reasoning Rail Introduce structured prompt schema for future reasoning steps. Prompt schema validated via JSON Schema tests. Trust Centre Signed schema manifests stored in Harbor with provenance metadata. Signed manifests visible and retrievable via digest. Other Map scanner outputs to explainable assurance categories. 100% of outputs mapped to unified severity scale."},{"location":"getting%20started/roadmap/#c-contextual-enrichment-threat-intelligence","title":"\ud83d\udfe1 C \u2014 Contextual Enrichment &amp; Threat Intelligence","text":"<p> Goal: Enrich normalized findings with contextual metadata and threat intelligence feeds.</p> Category Focus / Deliverables Success Criteria Core Platform Enrichment microservice for service, environment, and component metadata. Deployed enrichment service producing contextual labels. Orchestration Pipeline Integrate EPSS, KEV, CVSS, and CWE threat feeds into enrichment workflow. Nightly jobs automatically ingest threat feeds. AI Reasoning Rail Generate reasoning traces (\u201cwhy a finding matters\u201d) validated via DeepEval. \u2265 80% of enriched findings have reasoning traces. Trust Centre Sign enriched artifacts and publish to WORM registry. Enriched artifacts signed and traceable by digest. Other Business/compliance mappings to frameworks (e.g., NIST 800-53). Completed mapping for at least one major framework."},{"location":"getting%20started/roadmap/#d-thin-ticket-sync-human-in-the-loop","title":"\u26aa D \u2014 Thin Ticket Sync &amp; Human-in-the-Loop","text":"<p> Goal: Integrate human interactions into the system.</p> Category Focus / Deliverables Success Criteria Core Platform Integrate OpenProject or Jira through sync microservice. Evidence-URI linking operational for all tickets. Orchestration Pipeline Automate waiver approval via Tekton pause/resume logic. Approval workflow completes with auditable trail. AI Reasoning Rail Generate AI-authored remediation summaries and risk narratives. AI outputs meet \u2265 0.9 faithfulness / \u2265 0.8 consistency. Trust Centre Store waiver artifacts and co-signed approvals in OCI registry. 100% of waivers co-signed and logged in Rekor. Other Human-in-the-loop approval logging integrated into dashboard. Reviewer co-signatures visible and exportable."},{"location":"getting%20started/roadmap/#e-assurance-evaluation-loop","title":"\u26aa E \u2014 Assurance Evaluation Loop","text":"<p> Goal: Establish automated assurance gates and reasoning validation feedback.</p> Category Focus / Deliverables Success Criteria Core Platform Deploy Policy-as-Code runtime (CUE / OPA). Policy engine operational inside cluster. Orchestration Pipeline Automated gate evaluation producing signed pass/fail reports. Gate results reproducible and versioned per manifest. AI Reasoning Rail AI analyzes assurance outcomes, validated via DeepEval + Guardrails. All reasoning outputs validated automatically. Trust Centre Sign evaluation outputs and link to manifest digest. 100% of evaluation results signed and timestamped. Other Dashboard visualizes compliance and gate outcomes. Live pass/fail metrics visible in Grafana."},{"location":"getting%20started/roadmap/#f-continuous-feedback-drift-detection","title":"\u26aa F \u2014 Continuous Feedback &amp; Drift Detection","text":"<p> Goal: Enable longitudinal tracking of reasoning and assurance quality across versions.</p> Category Focus / Deliverables Success Criteria Core Platform Implement Tekton CronJobs for continuous assurance. Daily drift scans complete successfully. Orchestration Pipeline Detect SBOM, manifest, and reasoning deltas. Alerts generated within SLA (&lt;15 min). AI Reasoning Rail Monitor semantic drift (\u0394 bias, \u0394 faithfulness). Alerts trigger for drift &gt; 5%. Trust Centre Auto-resign and re-timestamp drifted evidence. Updated signatures verified in Rekor. Other Slack/Jira notifications for drift events. Notifications received for 100% of drift cases."},{"location":"getting%20started/roadmap/#g-governance-metrics-reporting","title":"\u26aa G \u2014 Governance, Metrics &amp; Reporting","text":"<p> Goal: Establish visibility and accountability across assurance operations.</p> Category Focus / Deliverables Success Criteria Core Platform Unified Prometheus + Grafana dashboards. Dashboards accessible with all key KPIs. Orchestration Pipeline Monthly \u201cAssurance Report\u201d pipeline. Reports generated automatically each month. AI Reasoning Rail Include reasoning reliability and drift metrics. Governance report incorporates AI validation results. Trust Centre Signed summary artifacts stored immutably. 100% cryptographically verified reports. Other Governance review workflow. \u2265 90% report delivery compliance across cycles."},{"location":"getting%20started/roadmap/#legend","title":"Legend","text":""},{"location":"getting%20started/roadmap/#done","title":"\ud83d\udfe2 Done","text":""},{"location":"getting%20started/roadmap/#in-progress","title":"\ud83d\udd35 In Progress","text":""},{"location":"getting%20started/roadmap/#planning","title":"\ud83d\udfe1 Planning","text":""},{"location":"getting%20started/roadmap/#not-started","title":"\u26aa Not Started","text":""},{"location":"getting%20started/testing/","title":"Testing","text":"<p>Below is the proposed testing plan for the PoC. Not all testing will be done on day one, but most of the testing categories should be in use before the end of the \"Fly Phase\".</p>"},{"location":"getting%20started/testing/#foundational-baselines","title":"Foundational Baselines","text":"<p> Goal: Establish reproducibility and consistent environments for all assurance workflows.  </p> Category Details Approach - Validate environment reproducibility (<code>make test-env</code>)  - Snapshot tool versions (<code>bandit --version</code>, <code>trivy --version</code>, etc.)  - Run dependency hygiene checks: <code>poetry check</code>, <code>pip-audit</code>  - Verify documentation build integrity: <code>mkdocs build --strict</code> Expected Output - <code>baseline.json</code> and <code>baseline.hash</code> signed with Cosign  - Verification logs confirming environment consistency  - Dependency and documentation validation results"},{"location":"getting%20started/testing/#static-functional-testing","title":"Static &amp; Functional Testing","text":"<p> Goal: Ensure correctness, code safety, and maintainability at rest.  </p> Category Details Scope - Core Python modules (<code>ingest</code>, <code>retrieve</code>, <code>generate</code>, etc.)  - Security and code quality scans (SAST + linting + typing) Approach - Run unit tests with <code>pytest</code> (coverage &gt; 85%)  - Lint and format: <code>ruff</code>, <code>flake8</code>, <code>black</code>  - Type checks: <code>mypy</code>  - Code complexity: <code>radon cc -s src/</code>  - Detect unused code: <code>vulture</code>  - SAST: <code>bandit -r src/</code>  - Secrets: <code>gitleaks detect</code>  - Dependency CVEs: <code>trivy fs .</code> or <code>grype</code> Expected Output - Coverage and quality reports (JSON)  - Linting and complexity metrics  - Signed SARIF outputs  - OCI artifact: <code>oci://org/cap/static:&lt;commit-hash&gt;</code>"},{"location":"getting%20started/testing/#dynamic-runtime-security-testing","title":"Dynamic &amp; Runtime Security Testing","text":"<p> Goal: Identify exploitable vulnerabilities in live or running environments.  </p> Category Details Scope - FastAPI endpoints, dashboards, webhooks  - Authentication, rate limiting, input validation Approach - Deploy test environment via Dagger or Tekton  - DAST with OWASP ZAP  - Nuclei scans (<code>cves</code>, <code>exposures</code>, <code>misconfigurations</code>)  - Optional Burp Suite CI or fuzzers  - Performance regression: <code>pytest-benchmark</code> or <code>locust</code> Expected Output - DAST and Nuclei JSON/SARIF reports  - Runtime performance baselines  - OCI artifact: <code>oci://org/cap/dynamic:&lt;commit-hash&gt;</code>"},{"location":"getting%20started/testing/#infrastructure-iac-security-testing","title":"Infrastructure &amp; IaC Security Testing","text":"<p> Goal: Validate security and compliance of infrastructure-as-code and container configurations.  </p> Category Details Scope - Terraform, Kubernetes manifests, Dockerfiles, GitHub Actions Approach - Policy checks: <code>checkov -d infra/</code>, <code>tfsec</code>  - Image scanning: <code>trivy image myimage:latest</code>  - Config scanning: <code>trivy config .</code>  - Dockerfile linting: <code>hadolint Dockerfile</code>  - IaC validation: <code>terraform validate</code>, <code>kubectl apply --dry-run</code>  - Apply CIS or custom Assurance policies Expected Output - IaC and container reports (SARIF + JSON)  - Signed attestation: <code>oci://org/cap/infra:&lt;commit-hash&gt;</code>"},{"location":"getting%20started/testing/#integration-end-to-end-e2e-testing","title":"Integration &amp; End-to-End (E2E) Testing","text":"<p> Goal: Validate the entire assurance workflow from ingestion to reporting.  </p> Category Details Approach - Use golden repos with known vulnerabilities  - Execute <code>scan run --repo &lt;fixture&gt;</code>  - Compare deterministic outputs (<code>report.json</code>, <code>report.md</code>)  - Validate schema (Pydantic) and API contracts (Schemathesis)  - Verify signatures (Cosign) and reproducibility Expected Output - Signed E2E attestation: <code>oci://org/cap/e2e:&lt;commit-hash&gt;</code>  - Deterministic test outputs with verified signatures"},{"location":"getting%20started/testing/#assurance-integrity-non-repudiation","title":"Assurance Integrity &amp; Non-Repudiation","text":"<p> Goal: Verify the trustworthiness and provenance of all assurance artifacts.  </p> Category Details Approach - Verify Cosign signatures  - Rebuild provenance with In-Toto links  - Validate Rekor transparency logs  - Detect expired/invalid signatures  - Documentation audit: <code>interrogate</code>  - Remove stale code: <code>vulture</code> Expected Output - Provenance verification logs  - Signed verification evidence  - Documentation coverage report"},{"location":"getting%20started/testing/#ai-assurance-evaluation","title":"AI Assurance &amp; Evaluation","text":"<p> Goal: Validate reasoning reliability, explainability, and fairness in AI-assisted components.  </p> Category Details Approach - Evaluate EXPLAIN/FIX/SUMMARIZE chains (DeepEval)  - Faithfulness \u2265 0.9, Relevancy \u2265 0.85, Consistency \u2265 0.8, Safety = 0  - Schema and safety validation: GuardrailsAI / Promptfoo  - Data consistency: Pandera / Great Expectations  - Feature attribution: SHAP, LIME  - Sign prompt provenance Expected Output - DeepEval and Guardrails reports  - Drift and reasoning deltas  - OCI artifact: <code>oci://org/cap/ai-eval:&lt;commit-hash&gt;</code>"},{"location":"getting%20started/testing/#continuous-regression-drift-detection","title":"Continuous Regression &amp; Drift Detection","text":"<p> Goal: Detect drift in security posture, assurance logic, and AI reasoning quality.  </p> Category Details Approach - Scheduled assurance jobs  - Compare DeepEval metrics, SBOM diffs, manifests  - Mutation testing (<code>mutmut run</code>)  - Trigger re-evaluation if thresholds exceeded Expected Output - Drift reports (<code>drift.json</code>)  - Mutation testing score (\u226580%)  - OCI artifact: <code>oci://org/cap/drift:&lt;commit-hash&gt;</code>"},{"location":"getting%20started/testing/#human-in-the-loop-workflow-validation","title":"Human-in-the-Loop &amp; Workflow Validation","text":"<p> Goal: Validate manual approvals, waivers, and review workflows.  </p> Category Details Approach - Simulate analyst and approver interactions  - Validate RBAC and countersignatures  - Attempt unauthorized modifications  - Accessibility checks: <code>axe-core</code>, <code>lighthouse-ci</code>  - Verify signed waiver artifacts Expected Output - Workflow validation log  - Accessibility compliance report  - OCI artifact: <code>oci://org/cap/hitl:&lt;commit-hash&gt;</code>"},{"location":"getting%20started/testing/#chaos-resilience-testing","title":"Chaos &amp; Resilience Testing","text":"<p> Goal: Validate the reliability and resilience of the assurance pipeline.  </p> Category Details Scope - Registry downtime, corrupted artifacts, key rotation, interrupted pipelines Approach - Simulate failure and recovery  - Verify resumption and signature integrity  - Measure recovery time and stability Expected Output - Recovery and degradation reports  - Verified integrity logs  - OCI artifact: <code>oci://org/cap/chaos:&lt;commit-hash&gt;</code>"},{"location":"getting%20started/testing/#comprehensive-quality-audit-attestation","title":"Comprehensive Quality Audit &amp; Attestation","text":"<p> Goal: Produce a final aggregated quality and assurance attestation covering all phases.  </p> Category Details Approach - Aggregate results from all phases  - Consolidate performance, complexity, documentation  - Generate unified Quality Attestation (JSON + Markdown)  - Sign and store in OCI registry Expected Output - Unified quality summary  - Signed attestation: <code>oci://org/cap/quality:&lt;commit-hash&gt;</code>"},{"location":"getting%20started/testing/#unified-metrics-and-acceptance-criteria","title":"Unified Metrics and Acceptance Criteria","text":"Metric Tool/Source Target Description Test Coverage Pytest \u226585% Unit test completeness Linting &amp; Type Checks Ruff, Mypy 100% Static code correctness Complexity Threshold Radon \u226410 Maintainable code Mutation Score Mutmut \u226580% Test robustness Documentation Coverage Interrogate \u226580% Code clarity Performance Regression Pytest-benchmark &lt;20% diff Runtime stability AI Faithfulness DeepEval \u22650.9 Reasoning reliability Drift Detection Latency Pipeline logs &lt;24h Responsiveness Reviewer SLA Workflow logs \u226448h Human validation timeliness"},{"location":"getting%20started/testing/#governance-and-reporting","title":"Governance and Reporting","text":"<ul> <li>All phases emit signed evidence to <code>oci://org/cap/tests/&lt;run-id&gt;</code>.</li> <li>CI/CD pipelines push metrics to Prometheus/Grafana dashboards.</li> <li>Failed thresholds create automated Jira issues (P1\u2013P4).</li> <li>Monthly reports include:</li> <li>DeepEval reasoning metrics</li> <li>Drift deltas</li> <li>Mutation and coverage summaries</li> <li>Signature freshness status</li> </ul>"},{"location":"getting%20started/testing/#continuous-improvement-and-future-enhancements","title":"Continuous Improvement and Future Enhancements","text":"<ul> <li>Expand Fuzz Testing (code, prompts, manifests).</li> <li>Integrate runtime threat detection (Falco, eBPF).</li> <li>Develop adversarial LLM red-team tests.</li> <li>Add formal verification for Policy DSLs.</li> <li>Establish inter-org attestation replays for federated trust validation.</li> </ul>"}]}